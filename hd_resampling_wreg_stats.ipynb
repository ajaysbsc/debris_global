{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Resample debris thickness data to enable regional stats to be computed\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from scipy import ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import median_absolute_deviation\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "\n",
    "\n",
    "import debrisglobal.globaldebris_input as debris_prms\n",
    "from debrisglobal.glacfeat import GlacFeat, create_glacfeat\n",
    "from meltcurves import melt_fromdebris_func\n",
    "from meltcurves import debris_frommelt_func\n",
    "from spc_split_lists import split_list\n",
    "\n",
    "\n",
    "debug=False\n",
    "verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_and_std(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values-average)**2, weights=weights)\n",
    "    return average, variance**0.5\n",
    "\n",
    "\n",
    "def weighted_percentile(sorted_list, weights, percentile):\n",
    "    \"\"\"\n",
    "    Calculate weighted percentile of a sorted list\n",
    "    \"\"\"\n",
    "    weights_cumsum_norm_high = np.cumsum(weights) / np.sum(weights)\n",
    "#     print(weights_cumsum_norm_high)\n",
    "    weights_norm = weights / np.sum(weights)\n",
    "    weights_cumsum_norm_low = weights_cumsum_norm_high - weights_norm\n",
    "#     print(weights_cumsum_norm_low)\n",
    "    \n",
    "    percentile_idx_high = np.where(weights_cumsum_norm_high >= percentile)[0][0]\n",
    "#     print(percentile_idx_high)\n",
    "    percentile_idx_low = np.where(weights_cumsum_norm_low <= percentile)[0][-1]\n",
    "#     print(percentile_idx_low)\n",
    "    \n",
    "    if percentile_idx_low == percentile_idx_high:\n",
    "        value_percentile = sorted_list[percentile_idx_low]\n",
    "    else:\n",
    "        value_percentile = np.mean([sorted_list[percentile_idx_low], sorted_list[percentile_idx_high]])\n",
    "\n",
    "    return value_percentile\n",
    "\n",
    "\n",
    "def pickle_data(fn, data):\n",
    "    \"\"\"Pickle data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fn : str\n",
    "        filename including filepath\n",
    "    data : list, etc.\n",
    "        data to be pickled\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    .pkl file\n",
    "        saves .pkl file of the data\n",
    "    \"\"\"\n",
    "    with open(fn, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "#Function to generate a 3-panel plot for input arrays\n",
    "def plot_array(dem, clim=None, titles=None, cmap='inferno', label=None, overlay=None, fn=None, close_fig=True):\n",
    "    fig, ax = plt.subplots(1,1, sharex=True, sharey=True, figsize=(10,5))\n",
    "    alpha = 1.0\n",
    "    #Gray background\n",
    "    ax.set_facecolor('0.5')\n",
    "    #Force aspect ratio to match images\n",
    "    ax.set(aspect='equal')\n",
    "    #Turn off axes labels/ticks\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if titles is not None:\n",
    "        ax.set_title(titles[0])\n",
    "    #Plot background shaded relief map\n",
    "    if overlay is not None:\n",
    "        alpha = 0.7\n",
    "        ax.imshow(overlay, cmap='gray', clim=(1,255))\n",
    "    #Plot each array\n",
    "    im_list = [ax.imshow(dem, clim=clim, cmap=cmap, alpha=alpha)]\n",
    "    fig.tight_layout()\n",
    "    fig.colorbar(im_list[0], label=label, extend='both', shrink=0.5)\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn, bbox_inches='tight', pad_inches=0, dpi=150)\n",
    "    if close_fig:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi: 01\n",
      "hd_mean (+/- std): 0.4 +/- 0.61\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.0\n",
      "  hd percentile (0.16): 0.03\n",
      "  hd percentile (0.25): 0.05\n",
      "  hd percentile (0.5): 0.18\n",
      "  hd percentile (0.75): 0.46\n",
      "  hd percentile (0.84): 0.66\n",
      "  hd percentile (0.95): 1.73\n",
      "  hd percentile (0.975): 3.0\n",
      "hd_low_mean (+/- std): 0.24 +/- 0.33\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.01\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.12\n",
      "  hd_low percentile (0.75): 0.3\n",
      "  hd_low percentile (0.84): 0.42\n",
      "  hd_low percentile (0.95): 1.01\n",
      "  hd_low percentile (0.975): 1.51\n",
      "hd_high_mean (+/- std): 0.7 +/- 1.41\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.06\n",
      "  hd_high percentile (0.25): 0.08\n",
      "  hd_high percentile (0.5): 0.25\n",
      "  hd_high percentile (0.75): 0.63\n",
      "  hd_high percentile (0.84): 0.92\n",
      "  hd_high percentile (0.95): 2.87\n",
      "  hd_high percentile (0.975): 7.66\n",
      "mf_mean (+/- std): 0.6 +/- 0.48\n",
      "  mf percentile (0.025): 0.03\n",
      "  mf percentile (0.05): 0.05\n",
      "  mf percentile (0.16): 0.11\n",
      "  mf percentile (0.25): 0.18\n",
      "  mf percentile (0.5): 0.46\n",
      "  mf percentile (0.75): 1.0\n",
      "  mf percentile (0.84): 1.12\n",
      "  mf percentile (0.95): 1.47\n",
      "  mf percentile (0.975): 1.68\n",
      "mf_low_mean (+/- std): 0.69 +/- 0.47\n",
      "  mf_low percentile (0.025): 0.06\n",
      "  mf_low percentile (0.05): 0.08\n",
      "  mf_low percentile (0.16): 0.16\n",
      "  mf_low percentile (0.25): 0.26\n",
      "  mf_low percentile (0.5): 0.64\n",
      "  mf_low percentile (0.75): 1.0\n",
      "  mf_low percentile (0.84): 1.14\n",
      "  mf_low percentile (0.95): 1.5\n",
      "  mf_low percentile (0.975): 1.69\n",
      "mf_high_mean (+/- std): 0.5 +/- 0.45\n",
      "  mf_high percentile (0.025): 0.01\n",
      "  mf_high percentile (0.05): 0.03\n",
      "  mf_high percentile (0.16): 0.08\n",
      "  mf_high percentile (0.25): 0.13\n",
      "  mf_high percentile (0.5): 0.35\n",
      "  mf_high percentile (0.75): 0.8\n",
      "  mf_high percentile (0.84): 1.01\n",
      "  mf_high percentile (0.95): 1.38\n",
      "  mf_high percentile (0.975): 1.58\n",
      "\n",
      "\n",
      "roi: 02\n",
      "hd_mean (+/- std): 0.28 +/- 0.45\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.01\n",
      "  hd percentile (0.16): 0.03\n",
      "  hd percentile (0.25): 0.06\n",
      "  hd percentile (0.5): 0.15\n",
      "  hd percentile (0.75): 0.3\n",
      "  hd percentile (0.84): 0.42\n",
      "  hd percentile (0.95): 0.97\n",
      "  hd percentile (0.975): 1.6\n",
      "hd_low_mean (+/- std): 0.17 +/- 0.25\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.01\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.09\n",
      "  hd_low percentile (0.75): 0.2\n",
      "  hd_low percentile (0.84): 0.27\n",
      "  hd_low percentile (0.95): 0.61\n",
      "  hd_low percentile (0.975): 0.95\n",
      "hd_high_mean (+/- std): 0.45 +/- 0.99\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.06\n",
      "  hd_high percentile (0.25): 0.09\n",
      "  hd_high percentile (0.5): 0.21\n",
      "  hd_high percentile (0.75): 0.41\n",
      "  hd_high percentile (0.84): 0.58\n",
      "  hd_high percentile (0.95): 1.4\n",
      "  hd_high percentile (0.975): 2.57\n",
      "mf_mean (+/- std): 0.66 +/- 0.45\n",
      "  mf percentile (0.025): 0.06\n",
      "  mf percentile (0.05): 0.1\n",
      "  mf percentile (0.16): 0.22\n",
      "  mf percentile (0.25): 0.3\n",
      "  mf percentile (0.5): 0.53\n",
      "  mf percentile (0.75): 1.03\n",
      "  mf percentile (0.84): 1.18\n",
      "  mf percentile (0.95): 1.49\n",
      "  mf percentile (0.975): 1.62\n",
      "mf_low_mean (+/- std): 0.77 +/- 0.42\n",
      "  mf_low percentile (0.025): 0.11\n",
      "  mf_low percentile (0.05): 0.16\n",
      "  mf_low percentile (0.16): 0.32\n",
      "  mf_low percentile (0.25): 0.43\n",
      "  mf_low percentile (0.5): 0.74\n",
      "  mf_low percentile (0.75): 1.06\n",
      "  mf_low percentile (0.84): 1.2\n",
      "  mf_low percentile (0.95): 1.5\n",
      "  mf_low percentile (0.975): 1.62\n",
      "mf_high_mean (+/- std): 0.53 +/- 0.4\n",
      "  mf_high percentile (0.025): 0.04\n",
      "  mf_high percentile (0.05): 0.07\n",
      "  mf_high percentile (0.16): 0.16\n",
      "  mf_high percentile (0.25): 0.23\n",
      "  mf_high percentile (0.5): 0.4\n",
      "  mf_high percentile (0.75): 0.78\n",
      "  mf_high percentile (0.84): 1.04\n",
      "  mf_high percentile (0.95): 1.34\n",
      "  mf_high percentile (0.975): 1.47\n",
      "\n",
      "\n",
      "roi: 03\n",
      "hd_mean (+/- std): 0.3 +/- 0.5\n",
      "  hd percentile (0.025): 0.01\n",
      "  hd percentile (0.05): 0.02\n",
      "  hd percentile (0.16): 0.05\n",
      "  hd percentile (0.25): 0.07\n",
      "  hd percentile (0.5): 0.15\n",
      "  hd percentile (0.75): 0.28\n",
      "  hd percentile (0.84): 0.41\n",
      "  hd percentile (0.95): 1.09\n",
      "  hd percentile (0.975): 2.2\n",
      "hd_low_mean (+/- std): 0.18 +/- 0.27\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0.0\n",
      "  hd_low percentile (0.16): 0.03\n",
      "  hd_low percentile (0.25): 0.04\n",
      "  hd_low percentile (0.5): 0.09\n",
      "  hd_low percentile (0.75): 0.18\n",
      "  hd_low percentile (0.84): 0.27\n",
      "  hd_low percentile (0.95): 0.68\n",
      "  hd_low percentile (0.975): 1.22\n",
      "hd_high_mean (+/- std): 0.5 +/- 1.16\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.08\n",
      "  hd_high percentile (0.25): 0.11\n",
      "  hd_high percentile (0.5): 0.21\n",
      "  hd_high percentile (0.75): 0.39\n",
      "  hd_high percentile (0.84): 0.57\n",
      "  hd_high percentile (0.95): 1.59\n",
      "  hd_high percentile (0.975): 4.15\n",
      "mf_mean (+/- std): 0.52 +/- 0.34\n",
      "  mf percentile (0.025): 0.04\n",
      "  mf percentile (0.05): 0.07\n",
      "  mf percentile (0.16): 0.18\n",
      "  mf percentile (0.25): 0.24\n",
      "  mf percentile (0.5): 0.44\n",
      "  mf percentile (0.75): 0.77\n",
      "  mf percentile (0.84): 0.95\n",
      "  mf percentile (0.95): 1.12\n",
      "  mf percentile (0.975): 1.23\n",
      "mf_low_mean (+/- std): 0.65 +/- 0.36\n",
      "  mf_low percentile (0.025): 0.06\n",
      "  mf_low percentile (0.05): 0.11\n",
      "  mf_low percentile (0.16): 0.26\n",
      "  mf_low percentile (0.25): 0.35\n",
      "  mf_low percentile (0.5): 0.62\n",
      "  mf_low percentile (0.75): 1.0\n",
      "  mf_low percentile (0.84): 1.04\n",
      "  mf_low percentile (0.95): 1.24\n",
      "  mf_low percentile (0.975): 1.31\n",
      "mf_high_mean (+/- std): 0.41 +/- 0.29\n",
      "  mf_high percentile (0.025): 0.02\n",
      "  mf_high percentile (0.05): 0.05\n",
      "  mf_high percentile (0.16): 0.13\n",
      "  mf_high percentile (0.25): 0.18\n",
      "  mf_high percentile (0.5): 0.33\n",
      "  mf_high percentile (0.75): 0.58\n",
      "  mf_high percentile (0.84): 0.71\n",
      "  mf_high percentile (0.95): 0.93\n",
      "  mf_high percentile (0.975): 1.11\n",
      "\n",
      "\n",
      "roi: 04\n",
      "hd_mean (+/- std): 0.32 +/- 0.5\n",
      "  hd percentile (0.025): 0.01\n",
      "  hd percentile (0.05): 0.02\n",
      "  hd percentile (0.16): 0.04\n",
      "  hd percentile (0.25): 0.07\n",
      "  hd percentile (0.5): 0.15\n",
      "  hd percentile (0.75): 0.33\n",
      "  hd percentile (0.84): 0.5\n",
      "  hd percentile (0.95): 1.22\n",
      "  hd percentile (0.975): 2.03\n",
      "hd_low_mean (+/- std): 0.19 +/- 0.27\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0.0\n",
      "  hd_low percentile (0.16): 0.02\n",
      "  hd_low percentile (0.25): 0.04\n",
      "  hd_low percentile (0.5): 0.09\n",
      "  hd_low percentile (0.75): 0.22\n",
      "  hd_low percentile (0.84): 0.32\n",
      "  hd_low percentile (0.95): 0.75\n",
      "  hd_low percentile (0.975): 1.15\n",
      "hd_high_mean (+/- std): 0.53 +/- 1.11\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.07\n",
      "  hd_high percentile (0.25): 0.11\n",
      "  hd_high percentile (0.5): 0.21\n",
      "  hd_high percentile (0.75): 0.45\n",
      "  hd_high percentile (0.84): 0.69\n",
      "  hd_high percentile (0.95): 1.82\n",
      "  hd_high percentile (0.975): 3.64\n",
      "mf_mean (+/- std): 0.55 +/- 0.37\n",
      "  mf percentile (0.025): 0.05\n",
      "  mf percentile (0.05): 0.08\n",
      "  mf percentile (0.16): 0.18\n",
      "  mf percentile (0.25): 0.25\n",
      "  mf percentile (0.5): 0.47\n",
      "  mf percentile (0.75): 0.8\n",
      "  mf percentile (0.84): 0.97\n",
      "  mf percentile (0.95): 1.25\n",
      "  mf percentile (0.975): 1.37\n",
      "mf_low_mean (+/- std): 0.69 +/- 0.38\n",
      "  mf_low percentile (0.025): 0.09\n",
      "  mf_low percentile (0.05): 0.13\n",
      "  mf_low percentile (0.16): 0.27\n",
      "  mf_low percentile (0.25): 0.37\n",
      "  mf_low percentile (0.5): 0.67\n",
      "  mf_low percentile (0.75): 1.0\n",
      "  mf_low percentile (0.84): 1.09\n",
      "  mf_low percentile (0.95): 1.31\n",
      "  mf_low percentile (0.975): 1.42\n",
      "mf_high_mean (+/- std): 0.42 +/- 0.3\n",
      "  mf_high percentile (0.025): 0.03\n",
      "  mf_high percentile (0.05): 0.06\n",
      "  mf_high percentile (0.16): 0.13\n",
      "  mf_high percentile (0.25): 0.19\n",
      "  mf_high percentile (0.5): 0.36\n",
      "  mf_high percentile (0.75): 0.59\n",
      "  mf_high percentile (0.84): 0.71\n",
      "  mf_high percentile (0.95): 1.05\n",
      "  mf_high percentile (0.975): 1.17\n",
      "\n",
      "\n",
      "roi: 05\n",
      "hd_mean (+/- std): 0.21 +/- 0.41\n",
      "  hd percentile (0.025): 0\n",
      "  hd percentile (0.05): 0\n",
      "  hd percentile (0.16): 0.01\n",
      "  hd percentile (0.25): 0.03\n",
      "  hd percentile (0.5): 0.1\n",
      "  hd percentile (0.75): 0.22\n",
      "  hd percentile (0.84): 0.33\n",
      "  hd percentile (0.95): 0.79\n",
      "  hd percentile (0.975): 1.3\n",
      "hd_low_mean (+/- std): 0.13 +/- 0.22\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hd_low percentile (0.25): 0.01\n",
      "  hd_low percentile (0.5): 0.06\n",
      "  hd_low percentile (0.75): 0.14\n",
      "  hd_low percentile (0.84): 0.22\n",
      "  hd_low percentile (0.95): 0.5\n",
      "  hd_low percentile (0.975): 0.79\n",
      "hd_high_mean (+/- std): 0.36 +/- 0.89\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.04\n",
      "  hd_high percentile (0.25): 0.06\n",
      "  hd_high percentile (0.5): 0.15\n",
      "  hd_high percentile (0.75): 0.31\n",
      "  hd_high percentile (0.84): 0.45\n",
      "  hd_high percentile (0.95): 1.11\n",
      "  hd_high percentile (0.975): 1.97\n",
      "mf_mean (+/- std): 0.79 +/- 0.43\n",
      "  mf percentile (0.025): 0.09\n",
      "  mf percentile (0.05): 0.15\n",
      "  mf percentile (0.16): 0.31\n",
      "  mf percentile (0.25): 0.43\n",
      "  mf percentile (0.5): 0.79\n",
      "  mf percentile (0.75): 1.01\n",
      "  mf percentile (0.84): 1.19\n",
      "  mf percentile (0.95): 1.53\n",
      "  mf percentile (0.975): 1.67\n",
      "mf_low_mean (+/- std): 0.9 +/- 0.4\n",
      "  mf_low percentile (0.025): 0.15\n",
      "  mf_low percentile (0.05): 0.22\n",
      "  mf_low percentile (0.16): 0.44\n",
      "  mf_low percentile (0.25): 0.6\n",
      "  mf_low percentile (0.5): 1.0\n",
      "  mf_low percentile (0.75): 1.14\n",
      "  mf_low percentile (0.84): 1.26\n",
      "  mf_low percentile (0.95): 1.56\n",
      "  mf_low percentile (0.975): 1.69\n",
      "mf_high_mean (+/- std): 0.69 +/- 0.43\n",
      "  mf_high percentile (0.025): 0.06\n",
      "  mf_high percentile (0.05): 0.11\n",
      "  mf_high percentile (0.16): 0.24\n",
      "  mf_high percentile (0.25): 0.33\n",
      "  mf_high percentile (0.5): 0.61\n",
      "  mf_high percentile (0.75): 1.08\n",
      "  mf_high percentile (0.84): 1.25\n",
      "  mf_high percentile (0.95): 1.37\n",
      "  mf_high percentile (0.975): 1.51\n",
      "\n",
      "\n",
      "roi: 06\n",
      "hd_mean (+/- std): 0.33 +/- 0.59\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.01\n",
      "  hd percentile (0.16): 0.03\n",
      "  hd percentile (0.25): 0.05\n",
      "  hd percentile (0.5): 0.13\n",
      "  hd percentile (0.75): 0.3\n",
      "  hd percentile (0.84): 0.47\n",
      "  hd percentile (0.95): 1.57\n",
      "  hd percentile (0.975): 3.0\n",
      "hd_low_mean (+/- std): 0.19 +/- 0.31\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.01\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.08\n",
      "  hd_low percentile (0.75): 0.2\n",
      "  hd_low percentile (0.84): 0.3\n",
      "  hd_low percentile (0.95): 0.93\n",
      "  hd_low percentile (0.975): 1.51\n",
      "hd_high_mean (+/- std): 0.58 +/- 1.35\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.06\n",
      "  hd_high percentile (0.25): 0.08\n",
      "  hd_high percentile (0.5): 0.19\n",
      "  hd_high percentile (0.75): 0.41\n",
      "  hd_high percentile (0.84): 0.65\n",
      "  hd_high percentile (0.95): 2.51\n",
      "  hd_high percentile (0.975): 7.66\n",
      "mf_mean (+/- std): 0.39 +/- 0.32\n",
      "  mf percentile (0.025): 0.02\n",
      "  mf percentile (0.05): 0.03\n",
      "  mf percentile (0.16): 0.09\n",
      "  mf percentile (0.25): 0.13\n",
      "  mf percentile (0.5): 0.29\n",
      "  mf percentile (0.75): 0.6\n",
      "  mf percentile (0.84): 0.84\n",
      "  mf percentile (0.95): 0.99\n",
      "  mf percentile (0.975): 1.0\n",
      "mf_low_mean (+/- std): 0.5 +/- 0.34\n",
      "  mf_low percentile (0.025): 0.03\n",
      "  mf_low percentile (0.05): 0.05\n",
      "  mf_low percentile (0.16): 0.13\n",
      "  mf_low percentile (0.25): 0.2\n",
      "  mf_low percentile (0.5): 0.42\n",
      "  mf_low percentile (0.75): 0.86\n",
      "  mf_low percentile (0.84): 0.97\n",
      "  mf_low percentile (0.95): 1.0\n",
      "  mf_low percentile (0.975): 1.0\n",
      "mf_high_mean (+/- std): 0.28 +/- 0.22\n",
      "  mf_high percentile (0.025): 0.01\n",
      "  mf_high percentile (0.05): 0.02\n",
      "  mf_high percentile (0.16): 0.07\n",
      "  mf_high percentile (0.25): 0.1\n",
      "  mf_high percentile (0.5): 0.21\n",
      "  mf_high percentile (0.75): 0.43\n",
      "  mf_high percentile (0.84): 0.6\n",
      "  mf_high percentile (0.95): 0.69\n",
      "  mf_high percentile (0.975): 0.74\n",
      "\n",
      "\n",
      "roi: 07\n",
      "hd_mean (+/- std): 0.38 +/- 0.73\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.01\n",
      "  hd percentile (0.16): 0.02\n",
      "  hd percentile (0.25): 0.03\n",
      "  hd percentile (0.5): 0.09\n",
      "  hd percentile (0.75): 0.3\n",
      "  hd percentile (0.84): 0.56\n",
      "  hd percentile (0.95): 2.93\n",
      "  hd percentile (0.975): 3.0\n",
      "hd_low_mean (+/- std): 0.21 +/- 0.38\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.0\n",
      "  hd_low percentile (0.25): 0.01\n",
      "  hd_low percentile (0.5): 0.05\n",
      "  hd_low percentile (0.75): 0.2\n",
      "  hd_low percentile (0.84): 0.36\n",
      "  hd_low percentile (0.95): 1.49\n",
      "  hd_low percentile (0.975): 1.51\n",
      "hd_high_mean (+/- std): 0.74 +/- 1.75\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.04\n",
      "  hd_high percentile (0.25): 0.06\n",
      "  hd_high percentile (0.5): 0.13\n",
      "  hd_high percentile (0.75): 0.41\n",
      "  hd_high percentile (0.84): 0.77\n",
      "  hd_high percentile (0.95): 7.25\n",
      "  hd_high percentile (0.975): 7.66\n",
      "mf_mean (+/- std): 0.64 +/- 0.41\n",
      "  mf percentile (0.025): 0.03\n",
      "  mf percentile (0.05): 0.04\n",
      "  mf percentile (0.16): 0.15\n",
      "  mf percentile (0.25): 0.25\n",
      "  mf percentile (0.5): 0.62\n",
      "  mf percentile (0.75): 1.02\n",
      "  mf percentile (0.84): 1.11\n",
      "  mf percentile (0.95): 1.27\n",
      "  mf percentile (0.975): 1.33\n",
      "mf_low_mean (+/- std): 0.73 +/- 0.4\n",
      "  mf_low percentile (0.025): 0.06\n",
      "  mf_low percentile (0.05): 0.07\n",
      "  mf_low percentile (0.16): 0.22\n",
      "  mf_low percentile (0.25): 0.36\n",
      "  mf_low percentile (0.5): 0.85\n",
      "  mf_low percentile (0.75): 1.03\n",
      "  mf_low percentile (0.84): 1.1\n",
      "  mf_low percentile (0.95): 1.27\n",
      "  mf_low percentile (0.975): 1.33\n",
      "mf_high_mean (+/- std): 0.5 +/- 0.35\n",
      "  mf_high percentile (0.025): 0.01\n",
      "  mf_high percentile (0.05): 0.02\n",
      "  mf_high percentile (0.16): 0.11\n",
      "  mf_high percentile (0.25): 0.19\n",
      "  mf_high percentile (0.5): 0.47\n",
      "  mf_high percentile (0.75): 0.8\n",
      "  mf_high percentile (0.84): 0.9\n",
      "  mf_high percentile (0.95): 1.08\n",
      "  mf_high percentile (0.975): 1.12\n",
      "\n",
      "\n",
      "roi: 08\n",
      "hd_mean (+/- std): 0.29 +/- 0.43\n",
      "  hd percentile (0.025): 0.01\n",
      "  hd percentile (0.05): 0.01\n",
      "  hd percentile (0.16): 0.04\n",
      "  hd percentile (0.25): 0.06\n",
      "  hd percentile (0.5): 0.14\n",
      "  hd percentile (0.75): 0.32\n",
      "  hd percentile (0.84): 0.46\n",
      "  hd percentile (0.95): 1.03\n",
      "  hd percentile (0.975): 1.54\n",
      "hd_low_mean (+/- std): 0.17 +/- 0.24\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.02\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.09\n",
      "  hd_low percentile (0.75): 0.21\n",
      "  hd_low percentile (0.84): 0.3\n",
      "  hd_low percentile (0.95): 0.64\n",
      "  hd_low percentile (0.975): 0.92\n",
      "hd_high_mean (+/- std): 0.45 +/- 0.89\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.07\n",
      "  hd_high percentile (0.25): 0.09\n",
      "  hd_high percentile (0.5): 0.2\n",
      "  hd_high percentile (0.75): 0.44\n",
      "  hd_high percentile (0.84): 0.63\n",
      "  hd_high percentile (0.95): 1.49\n",
      "  hd_high percentile (0.975): 2.44\n",
      "mf_mean (+/- std): 0.54 +/- 0.37\n",
      "  mf percentile (0.025): 0.05\n",
      "  mf percentile (0.05): 0.08\n",
      "  mf percentile (0.16): 0.17\n",
      "  mf percentile (0.25): 0.23\n",
      "  mf percentile (0.5): 0.45\n",
      "  mf percentile (0.75): 0.82\n",
      "  mf percentile (0.84): 1.03\n",
      "  mf percentile (0.95): 1.21\n",
      "  mf percentile (0.975): 1.25\n",
      "mf_low_mean (+/- std): 0.66 +/- 0.36\n",
      "  mf_low percentile (0.025): 0.09\n",
      "  mf_low percentile (0.05): 0.12\n",
      "  mf_low percentile (0.16): 0.25\n",
      "  mf_low percentile (0.25): 0.33\n",
      "  mf_low percentile (0.5): 0.65\n",
      "  mf_low percentile (0.75): 1.0\n",
      "  mf_low percentile (0.84): 1.06\n",
      "  mf_low percentile (0.95): 1.24\n",
      "  mf_low percentile (0.975): 1.24\n",
      "mf_high_mean (+/- std): 0.42 +/- 0.29\n",
      "  mf_high percentile (0.025): 0.03\n",
      "  mf_high percentile (0.05): 0.06\n",
      "  mf_high percentile (0.16): 0.12\n",
      "  mf_high percentile (0.25): 0.17\n",
      "  mf_high percentile (0.5): 0.35\n",
      "  mf_high percentile (0.75): 0.61\n",
      "  mf_high percentile (0.84): 0.76\n",
      "  mf_high percentile (0.95): 0.97\n",
      "  mf_high percentile (0.975): 0.99\n",
      "\n",
      "\n",
      "roi: 09\n",
      "hd_mean (+/- std): 0.18 +/- 0.4\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.0\n",
      "  hd percentile (0.16): 0.01\n",
      "  hd percentile (0.25): 0.02\n",
      "  hd percentile (0.5): 0.05\n",
      "  hd percentile (0.75): 0.16\n",
      "  hd percentile (0.84): 0.27\n",
      "  hd percentile (0.95): 0.79\n",
      "  hd percentile (0.975): 1.3\n",
      "hd_low_mean (+/- std): 0.11 +/- 0.22\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0\n",
      "  hd_low percentile (0.25): 0.0\n",
      "  hd_low percentile (0.5): 0.03\n",
      "  hd_low percentile (0.75): 0.1\n",
      "  hd_low percentile (0.84): 0.18\n",
      "  hd_low percentile (0.95): 0.5\n",
      "  hd_low percentile (0.975): 0.79\n",
      "hd_high_mean (+/- std): 0.31 +/- 0.84\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.04\n",
      "  hd_high percentile (0.25): 0.04\n",
      "  hd_high percentile (0.5): 0.08\n",
      "  hd_high percentile (0.75): 0.23\n",
      "  hd_high percentile (0.84): 0.37\n",
      "  hd_high percentile (0.95): 1.11\n",
      "  hd_high percentile (0.975): 1.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf_mean (+/- std): 0.7 +/- 0.37\n",
      "  mf percentile (0.025): 0.06\n",
      "  mf percentile (0.05): 0.09\n",
      "  mf percentile (0.16): 0.23\n",
      "  mf percentile (0.25): 0.35\n",
      "  mf percentile (0.5): 0.78\n",
      "  mf percentile (0.75): 1.02\n",
      "  mf percentile (0.84): 1.05\n",
      "  mf percentile (0.95): 1.18\n",
      "  mf percentile (0.975): 1.29\n",
      "mf_low_mean (+/- std): 0.79 +/- 0.34\n",
      "  mf_low percentile (0.025): 0.09\n",
      "  mf_low percentile (0.05): 0.14\n",
      "  mf_low percentile (0.16): 0.33\n",
      "  mf_low percentile (0.25): 0.51\n",
      "  mf_low percentile (0.5): 0.99\n",
      "  mf_low percentile (0.75): 1.01\n",
      "  mf_low percentile (0.84): 1.03\n",
      "  mf_low percentile (0.95): 1.18\n",
      "  mf_low percentile (0.975): 1.25\n",
      "mf_high_mean (+/- std): 0.52 +/- 0.29\n",
      "  mf_high percentile (0.025): 0.04\n",
      "  mf_high percentile (0.05): 0.07\n",
      "  mf_high percentile (0.16): 0.17\n",
      "  mf_high percentile (0.25): 0.26\n",
      "  mf_high percentile (0.5): 0.55\n",
      "  mf_high percentile (0.75): 0.77\n",
      "  mf_high percentile (0.84): 0.84\n",
      "  mf_high percentile (0.95): 0.97\n",
      "  mf_high percentile (0.975): 1.07\n",
      "\n",
      "\n",
      "roi: 10\n",
      "hd_mean (+/- std): 0.09 +/- 0.17\n",
      "  hd percentile (0.025): 0\n",
      "  hd percentile (0.05): 0\n",
      "  hd percentile (0.16): 0\n",
      "  hd percentile (0.25): 0.0\n",
      "  hd percentile (0.5): 0.04\n",
      "  hd percentile (0.75): 0.12\n",
      "  hd percentile (0.84): 0.17\n",
      "  hd percentile (0.95): 0.36\n",
      "  hd percentile (0.975): 0.53\n",
      "hd_low_mean (+/- std): 0.06 +/- 0.11\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0\n",
      "  hd_low percentile (0.25): 0\n",
      "  hd_low percentile (0.5): 0.02\n",
      "  hd_low percentile (0.75): 0.07\n",
      "  hd_low percentile (0.84): 0.11\n",
      "  hd_low percentile (0.95): 0.24\n",
      "  hd_low percentile (0.975): 0.34\n",
      "hd_high_mean (+/- std): 0.15 +/- 0.24\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.04\n",
      "  hd_high percentile (0.25): 0.04\n",
      "  hd_high percentile (0.5): 0.07\n",
      "  hd_high percentile (0.75): 0.17\n",
      "  hd_high percentile (0.84): 0.24\n",
      "  hd_high percentile (0.95): 0.5\n",
      "  hd_high percentile (0.975): 0.73\n",
      "mf_mean (+/- std): 0.8 +/- 0.34\n",
      "  mf percentile (0.025): 0.13\n",
      "  mf percentile (0.05): 0.18\n",
      "  mf percentile (0.16): 0.36\n",
      "  mf percentile (0.25): 0.5\n",
      "  mf percentile (0.5): 1.0\n",
      "  mf percentile (0.75): 1.04\n",
      "  mf percentile (0.84): 1.11\n",
      "  mf percentile (0.95): 1.21\n",
      "  mf percentile (0.975): 1.23\n",
      "mf_low_mean (+/- std): 0.88 +/- 0.29\n",
      "  mf_low percentile (0.025): 0.19\n",
      "  mf_low percentile (0.05): 0.26\n",
      "  mf_low percentile (0.16): 0.52\n",
      "  mf_low percentile (0.25): 0.72\n",
      "  mf_low percentile (0.5): 1.0\n",
      "  mf_low percentile (0.75): 1.03\n",
      "  mf_low percentile (0.84): 1.11\n",
      "  mf_low percentile (0.95): 1.21\n",
      "  mf_low percentile (0.975): 1.22\n",
      "mf_high_mean (+/- std): 0.68 +/- 0.33\n",
      "  mf_high percentile (0.025): 0.09\n",
      "  mf_high percentile (0.05): 0.13\n",
      "  mf_high percentile (0.16): 0.26\n",
      "  mf_high percentile (0.25): 0.37\n",
      "  mf_high percentile (0.5): 0.8\n",
      "  mf_high percentile (0.75): 0.97\n",
      "  mf_high percentile (0.84): 0.97\n",
      "  mf_high percentile (0.95): 1.06\n",
      "  mf_high percentile (0.975): 1.06\n",
      "\n",
      "\n",
      "roi: 11\n",
      "hd_mean (+/- std): 0.23 +/- 0.34\n",
      "  hd percentile (0.025): 0.01\n",
      "  hd percentile (0.05): 0.01\n",
      "  hd percentile (0.16): 0.03\n",
      "  hd percentile (0.25): 0.05\n",
      "  hd percentile (0.5): 0.13\n",
      "  hd percentile (0.75): 0.27\n",
      "  hd percentile (0.84): 0.38\n",
      "  hd percentile (0.95): 0.74\n",
      "  hd percentile (0.975): 1.05\n",
      "hd_low_mean (+/- std): 0.14 +/- 0.2\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.01\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.08\n",
      "  hd_low percentile (0.75): 0.18\n",
      "  hd_low percentile (0.84): 0.25\n",
      "  hd_low percentile (0.95): 0.47\n",
      "  hd_low percentile (0.975): 0.66\n",
      "hd_high_mean (+/- std): 0.35 +/- 0.69\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.06\n",
      "  hd_high percentile (0.25): 0.08\n",
      "  hd_high percentile (0.5): 0.19\n",
      "  hd_high percentile (0.75): 0.37\n",
      "  hd_high percentile (0.84): 0.52\n",
      "  hd_high percentile (0.95): 1.04\n",
      "  hd_high percentile (0.975): 1.52\n",
      "mf_mean (+/- std): 0.74 +/- 0.44\n",
      "  mf percentile (0.025): 0.1\n",
      "  mf percentile (0.05): 0.14\n",
      "  mf percentile (0.16): 0.27\n",
      "  mf percentile (0.25): 0.36\n",
      "  mf percentile (0.5): 0.65\n",
      "  mf percentile (0.75): 1.11\n",
      "  mf percentile (0.84): 1.27\n",
      "  mf percentile (0.95): 1.5\n",
      "  mf percentile (0.975): 1.58\n",
      "mf_low_mean (+/- std): 0.87 +/- 0.42\n",
      "  mf_low percentile (0.025): 0.16\n",
      "  mf_low percentile (0.05): 0.21\n",
      "  mf_low percentile (0.16): 0.39\n",
      "  mf_low percentile (0.25): 0.51\n",
      "  mf_low percentile (0.5): 0.91\n",
      "  mf_low percentile (0.75): 1.2\n",
      "  mf_low percentile (0.84): 1.34\n",
      "  mf_low percentile (0.95): 1.55\n",
      "  mf_low percentile (0.975): 1.6\n",
      "mf_high_mean (+/- std): 0.58 +/- 0.38\n",
      "  mf_high percentile (0.025): 0.07\n",
      "  mf_high percentile (0.05): 0.1\n",
      "  mf_high percentile (0.16): 0.2\n",
      "  mf_high percentile (0.25): 0.27\n",
      "  mf_high percentile (0.5): 0.5\n",
      "  mf_high percentile (0.75): 0.86\n",
      "  mf_high percentile (0.84): 1.06\n",
      "  mf_high percentile (0.95): 1.29\n",
      "  mf_high percentile (0.975): 1.37\n",
      "\n",
      "\n",
      "roi: 12\n",
      "hd_mean (+/- std): 0.32 +/- 0.49\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.01\n",
      "  hd percentile (0.16): 0.03\n",
      "  hd percentile (0.25): 0.06\n",
      "  hd percentile (0.5): 0.17\n",
      "  hd percentile (0.75): 0.36\n",
      "  hd percentile (0.84): 0.52\n",
      "  hd percentile (0.95): 1.12\n",
      "  hd percentile (0.975): 1.91\n",
      "hd_low_mean (+/- std): 0.19 +/- 0.27\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.01\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.11\n",
      "  hd_low percentile (0.75): 0.24\n",
      "  hd_low percentile (0.84): 0.34\n",
      "  hd_low percentile (0.95): 0.7\n",
      "  hd_low percentile (0.975): 1.09\n",
      "hd_high_mean (+/- std): 0.53 +/- 1.09\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.06\n",
      "  hd_high percentile (0.25): 0.09\n",
      "  hd_high percentile (0.5): 0.24\n",
      "  hd_high percentile (0.75): 0.5\n",
      "  hd_high percentile (0.84): 0.72\n",
      "  hd_high percentile (0.95): 1.65\n",
      "  hd_high percentile (0.975): 3.31\n",
      "mf_mean (+/- std): 0.59 +/- 0.41\n",
      "  mf percentile (0.025): 0.05\n",
      "  mf percentile (0.05): 0.09\n",
      "  mf percentile (0.16): 0.18\n",
      "  mf percentile (0.25): 0.25\n",
      "  mf percentile (0.5): 0.48\n",
      "  mf percentile (0.75): 0.96\n",
      "  mf percentile (0.84): 1.12\n",
      "  mf percentile (0.95): 1.31\n",
      "  mf percentile (0.975): 1.38\n",
      "mf_low_mean (+/- std): 0.7 +/- 0.38\n",
      "  mf_low percentile (0.025): 0.09\n",
      "  mf_low percentile (0.05): 0.14\n",
      "  mf_low percentile (0.16): 0.27\n",
      "  mf_low percentile (0.25): 0.36\n",
      "  mf_low percentile (0.5): 0.66\n",
      "  mf_low percentile (0.75): 1.0\n",
      "  mf_low percentile (0.84): 1.1\n",
      "  mf_low percentile (0.95): 1.29\n",
      "  mf_low percentile (0.975): 1.38\n",
      "mf_high_mean (+/- std): 0.48 +/- 0.36\n",
      "  mf_high percentile (0.025): 0.03\n",
      "  mf_high percentile (0.05): 0.06\n",
      "  mf_high percentile (0.16): 0.14\n",
      "  mf_high percentile (0.25): 0.19\n",
      "  mf_high percentile (0.5): 0.37\n",
      "  mf_high percentile (0.75): 0.72\n",
      "  mf_high percentile (0.84): 0.98\n",
      "  mf_high percentile (0.95): 1.13\n",
      "  mf_high percentile (0.975): 1.22\n",
      "\n",
      "\n",
      "roi: 13\n",
      "hd_mean (+/- std): 0.4 +/- 0.63\n",
      "  hd percentile (0.025): 0.01\n",
      "  hd percentile (0.05): 0.01\n",
      "  hd percentile (0.16): 0.04\n",
      "  hd percentile (0.25): 0.06\n",
      "  hd percentile (0.5): 0.18\n",
      "  hd percentile (0.75): 0.42\n",
      "  hd percentile (0.84): 0.64\n",
      "  hd percentile (0.95): 1.86\n",
      "  hd percentile (0.975): 3.0\n",
      "hd_low_mean (+/- std): 0.24 +/- 0.34\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.02\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.12\n",
      "  hd_low percentile (0.75): 0.27\n",
      "  hd_low percentile (0.84): 0.41\n",
      "  hd_low percentile (0.95): 1.07\n",
      "  hd_low percentile (0.975): 1.51\n",
      "hd_high_mean (+/- std): 0.72 +/- 1.48\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.07\n",
      "  hd_high percentile (0.25): 0.09\n",
      "  hd_high percentile (0.5): 0.25\n",
      "  hd_high percentile (0.75): 0.58\n",
      "  hd_high percentile (0.84): 0.89\n",
      "  hd_high percentile (0.95): 3.18\n",
      "  hd_high percentile (0.975): 7.66\n",
      "mf_mean (+/- std): 0.59 +/- 0.45\n",
      "  mf percentile (0.025): 0.04\n",
      "  mf percentile (0.05): 0.05\n",
      "  mf percentile (0.16): 0.14\n",
      "  mf percentile (0.25): 0.2\n",
      "  mf percentile (0.5): 0.45\n",
      "  mf percentile (0.75): 0.99\n",
      "  mf percentile (0.84): 1.17\n",
      "  mf percentile (0.95): 1.4\n",
      "  mf percentile (0.975): 1.51\n",
      "mf_low_mean (+/- std): 0.7 +/- 0.44\n",
      "  mf_low percentile (0.025): 0.07\n",
      "  mf_low percentile (0.05): 0.09\n",
      "  mf_low percentile (0.16): 0.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  mf_low percentile (0.25): 0.3\n",
      "  mf_low percentile (0.5): 0.64\n",
      "  mf_low percentile (0.75): 1.07\n",
      "  mf_low percentile (0.84): 1.21\n",
      "  mf_low percentile (0.95): 1.42\n",
      "  mf_low percentile (0.975): 1.51\n",
      "mf_high_mean (+/- std): 0.47 +/- 0.4\n",
      "  mf_high percentile (0.025): 0.02\n",
      "  mf_high percentile (0.05): 0.03\n",
      "  mf_high percentile (0.16): 0.1\n",
      "  mf_high percentile (0.25): 0.15\n",
      "  mf_high percentile (0.5): 0.33\n",
      "  mf_high percentile (0.75): 0.72\n",
      "  mf_high percentile (0.84): 0.99\n",
      "  mf_high percentile (0.95): 1.29\n",
      "  mf_high percentile (0.975): 1.38\n",
      "\n",
      "\n",
      "roi: 14\n",
      "hd_mean (+/- std): 0.36 +/- 0.57\n",
      "  hd percentile (0.025): 0.01\n",
      "  hd percentile (0.05): 0.01\n",
      "  hd percentile (0.16): 0.04\n",
      "  hd percentile (0.25): 0.06\n",
      "  hd percentile (0.5): 0.16\n",
      "  hd percentile (0.75): 0.4\n",
      "  hd percentile (0.84): 0.59\n",
      "  hd percentile (0.95): 1.4\n",
      "  hd percentile (0.975): 2.83\n",
      "hd_low_mean (+/- std): 0.21 +/- 0.31\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.02\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.1\n",
      "  hd_low percentile (0.75): 0.26\n",
      "  hd_low percentile (0.84): 0.38\n",
      "  hd_low percentile (0.95): 0.85\n",
      "  hd_low percentile (0.975): 1.45\n",
      "hd_high_mean (+/- std): 0.62 +/- 1.29\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.07\n",
      "  hd_high percentile (0.25): 0.09\n",
      "  hd_high percentile (0.5): 0.23\n",
      "  hd_high percentile (0.75): 0.55\n",
      "  hd_high percentile (0.84): 0.82\n",
      "  hd_high percentile (0.95): 2.16\n",
      "  hd_high percentile (0.975): 6.71\n",
      "mf_mean (+/- std): 0.72 +/- 0.51\n",
      "  mf percentile (0.025): 0.04\n",
      "  mf percentile (0.05): 0.08\n",
      "  mf percentile (0.16): 0.18\n",
      "  mf percentile (0.25): 0.27\n",
      "  mf percentile (0.5): 0.59\n",
      "  mf percentile (0.75): 1.14\n",
      "  mf percentile (0.84): 1.35\n",
      "  mf percentile (0.95): 1.62\n",
      "  mf percentile (0.975): 1.77\n",
      "mf_low_mean (+/- std): 0.84 +/- 0.49\n",
      "  mf_low percentile (0.025): 0.08\n",
      "  mf_low percentile (0.05): 0.13\n",
      "  mf_low percentile (0.16): 0.28\n",
      "  mf_low percentile (0.25): 0.39\n",
      "  mf_low percentile (0.5): 0.84\n",
      "  mf_low percentile (0.75): 1.21\n",
      "  mf_low percentile (0.84): 1.41\n",
      "  mf_low percentile (0.95): 1.66\n",
      "  mf_low percentile (0.975): 1.77\n",
      "mf_high_mean (+/- std): 0.59 +/- 0.47\n",
      "  mf_high percentile (0.025): 0.02\n",
      "  mf_high percentile (0.05): 0.05\n",
      "  mf_high percentile (0.16): 0.13\n",
      "  mf_high percentile (0.25): 0.2\n",
      "  mf_high percentile (0.5): 0.44\n",
      "  mf_high percentile (0.75): 0.89\n",
      "  mf_high percentile (0.84): 1.16\n",
      "  mf_high percentile (0.95): 1.51\n",
      "  mf_high percentile (0.975): 1.64\n",
      "\n",
      "\n",
      "roi: 15\n",
      "hd_mean (+/- std): 0.46 +/- 0.72\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.0\n",
      "  hd percentile (0.16): 0.02\n",
      "  hd percentile (0.25): 0.05\n",
      "  hd percentile (0.5): 0.19\n",
      "  hd percentile (0.75): 0.49\n",
      "  hd percentile (0.84): 0.78\n",
      "  hd percentile (0.95): 2.77\n",
      "  hd percentile (0.975): 3.0\n",
      "hd_low_mean (+/- std): 0.27 +/- 0.38\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.0\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.12\n",
      "  hd_low percentile (0.75): 0.32\n",
      "  hd_low percentile (0.84): 0.5\n",
      "  hd_low percentile (0.95): 1.43\n",
      "  hd_low percentile (0.975): 1.51\n",
      "hd_high_mean (+/- std): 0.86 +/- 1.73\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.04\n",
      "  hd_high percentile (0.25): 0.08\n",
      "  hd_high percentile (0.5): 0.27\n",
      "  hd_high percentile (0.75): 0.68\n",
      "  hd_high percentile (0.84): 1.1\n",
      "  hd_high percentile (0.95): 6.4\n",
      "  hd_high percentile (0.975): 7.66\n",
      "mf_mean (+/- std): 0.58 +/- 0.48\n",
      "  mf percentile (0.025): 0.03\n",
      "  mf percentile (0.05): 0.04\n",
      "  mf percentile (0.16): 0.11\n",
      "  mf percentile (0.25): 0.17\n",
      "  mf percentile (0.5): 0.42\n",
      "  mf percentile (0.75): 1.01\n",
      "  mf percentile (0.84): 1.14\n",
      "  mf percentile (0.95): 1.36\n",
      "  mf percentile (0.975): 1.45\n",
      "mf_low_mean (+/- std): 0.67 +/- 0.46\n",
      "  mf_low percentile (0.025): 0.06\n",
      "  mf_low percentile (0.05): 0.07\n",
      "  mf_low percentile (0.16): 0.17\n",
      "  mf_low percentile (0.25): 0.26\n",
      "  mf_low percentile (0.5): 0.6\n",
      "  mf_low percentile (0.75): 1.0\n",
      "  mf_low percentile (0.84): 1.14\n",
      "  mf_low percentile (0.95): 1.36\n",
      "  mf_low percentile (0.975): 1.45\n",
      "mf_high_mean (+/- std): 0.48 +/- 0.44\n",
      "  mf_high percentile (0.025): 0.01\n",
      "  mf_high percentile (0.05): 0.02\n",
      "  mf_high percentile (0.16): 0.08\n",
      "  mf_high percentile (0.25): 0.13\n",
      "  mf_high percentile (0.5): 0.32\n",
      "  mf_high percentile (0.75): 0.8\n",
      "  mf_high percentile (0.84): 1.06\n",
      "  mf_high percentile (0.95): 1.21\n",
      "  mf_high percentile (0.975): 1.33\n",
      "\n",
      "\n",
      "roi: 16\n",
      "hd_mean (+/- std): 0.24 +/- 0.45\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.0\n",
      "  hd percentile (0.16): 0.02\n",
      "  hd percentile (0.25): 0.04\n",
      "  hd percentile (0.5): 0.12\n",
      "  hd percentile (0.75): 0.24\n",
      "  hd percentile (0.84): 0.35\n",
      "  hd percentile (0.95): 0.85\n",
      "  hd percentile (0.975): 1.62\n",
      "hd_low_mean (+/- std): 0.15 +/- 0.24\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.0\n",
      "  hd_low percentile (0.25): 0.02\n",
      "  hd_low percentile (0.5): 0.07\n",
      "  hd_low percentile (0.75): 0.16\n",
      "  hd_low percentile (0.84): 0.23\n",
      "  hd_low percentile (0.95): 0.54\n",
      "  hd_low percentile (0.975): 0.96\n",
      "hd_high_mean (+/- std): 0.41 +/- 1.02\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.04\n",
      "  hd_high percentile (0.25): 0.07\n",
      "  hd_high percentile (0.5): 0.17\n",
      "  hd_high percentile (0.75): 0.33\n",
      "  hd_high percentile (0.84): 0.48\n",
      "  hd_high percentile (0.95): 1.2\n",
      "  hd_high percentile (0.975): 2.61\n",
      "mf_mean (+/- std): 0.55 +/- 0.34\n",
      "  mf percentile (0.025): 0.05\n",
      "  mf percentile (0.05): 0.09\n",
      "  mf percentile (0.16): 0.2\n",
      "  mf percentile (0.25): 0.27\n",
      "  mf percentile (0.5): 0.46\n",
      "  mf percentile (0.75): 0.87\n",
      "  mf percentile (0.84): 1.02\n",
      "  mf percentile (0.95): 1.1\n",
      "  mf percentile (0.975): 1.12\n",
      "mf_low_mean (+/- std): 0.66 +/- 0.33\n",
      "  mf_low percentile (0.025): 0.08\n",
      "  mf_low percentile (0.05): 0.13\n",
      "  mf_low percentile (0.16): 0.29\n",
      "  mf_low percentile (0.25): 0.38\n",
      "  mf_low percentile (0.5): 0.65\n",
      "  mf_low percentile (0.75): 1.0\n",
      "  mf_low percentile (0.84): 1.03\n",
      "  mf_low percentile (0.95): 1.11\n",
      "  mf_low percentile (0.975): 1.11\n",
      "mf_high_mean (+/- std): 0.43 +/- 0.28\n",
      "  mf_high percentile (0.025): 0.03\n",
      "  mf_high percentile (0.05): 0.06\n",
      "  mf_high percentile (0.16): 0.15\n",
      "  mf_high percentile (0.25): 0.2\n",
      "  mf_high percentile (0.5): 0.35\n",
      "  mf_high percentile (0.75): 0.68\n",
      "  mf_high percentile (0.84): 0.88\n",
      "  mf_high percentile (0.95): 0.88\n",
      "  mf_high percentile (0.975): 0.88\n",
      "\n",
      "\n",
      "roi: 17\n",
      "hd_mean (+/- std): 0.23 +/- 0.46\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.0\n",
      "  hd percentile (0.16): 0.02\n",
      "  hd percentile (0.25): 0.03\n",
      "  hd percentile (0.5): 0.1\n",
      "  hd percentile (0.75): 0.23\n",
      "  hd percentile (0.84): 0.33\n",
      "  hd percentile (0.95): 0.79\n",
      "  hd percentile (0.975): 1.67\n",
      "hd_low_mean (+/- std): 0.14 +/- 0.25\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.0\n",
      "  hd_low percentile (0.25): 0.01\n",
      "  hd_low percentile (0.5): 0.06\n",
      "  hd_low percentile (0.75): 0.15\n",
      "  hd_low percentile (0.84): 0.22\n",
      "  hd_low percentile (0.95): 0.5\n",
      "  hd_low percentile (0.975): 0.98\n",
      "hd_high_mean (+/- std): 0.4 +/- 1.07\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.04\n",
      "  hd_high percentile (0.25): 0.06\n",
      "  hd_high percentile (0.5): 0.15\n",
      "  hd_high percentile (0.75): 0.32\n",
      "  hd_high percentile (0.84): 0.45\n",
      "  hd_high percentile (0.95): 1.11\n",
      "  hd_high percentile (0.975): 2.73\n",
      "mf_mean (+/- std): 0.64 +/- 0.43\n",
      "  mf percentile (0.025): 0.03\n",
      "  mf percentile (0.05): 0.06\n",
      "  mf percentile (0.16): 0.2\n",
      "  mf percentile (0.25): 0.29\n",
      "  mf percentile (0.5): 0.58\n",
      "  mf percentile (0.75): 0.99\n",
      "  mf percentile (0.84): 1.03\n",
      "  mf percentile (0.95): 1.39\n",
      "  mf percentile (0.975): 1.66\n",
      "mf_low_mean (+/- std): 0.78 +/- 0.44\n",
      "  mf_low percentile (0.025): 0.04\n",
      "  mf_low percentile (0.05): 0.1\n",
      "  mf_low percentile (0.16): 0.29\n",
      "  mf_low percentile (0.25): 0.42\n",
      "  mf_low percentile (0.5): 0.82\n",
      "  mf_low percentile (0.75): 1.0\n",
      "  mf_low percentile (0.84): 1.09\n",
      "  mf_low percentile (0.95): 1.54\n",
      "  mf_low percentile (0.975): 1.81\n",
      "mf_high_mean (+/- std): 0.48 +/- 0.35\n",
      "  mf_high percentile (0.025): 0.02\n",
      "  mf_high percentile (0.05): 0.05\n",
      "  mf_high percentile (0.16): 0.15\n",
      "  mf_high percentile (0.25): 0.22\n",
      "  mf_high percentile (0.5): 0.4\n",
      "  mf_high percentile (0.75): 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  mf_high percentile (0.84): 0.78\n",
      "  mf_high percentile (0.95): 1.12\n",
      "  mf_high percentile (0.975): 1.33\n",
      "\n",
      "\n",
      "roi: 18\n",
      "hd_mean (+/- std): 0.29 +/- 0.4\n",
      "  hd percentile (0.025): 0.01\n",
      "  hd percentile (0.05): 0.02\n",
      "  hd percentile (0.16): 0.04\n",
      "  hd percentile (0.25): 0.06\n",
      "  hd percentile (0.5): 0.17\n",
      "  hd percentile (0.75): 0.37\n",
      "  hd percentile (0.84): 0.5\n",
      "  hd percentile (0.95): 0.94\n",
      "  hd percentile (0.975): 1.34\n",
      "hd_low_mean (+/- std): 0.18 +/- 0.23\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0.0\n",
      "  hd_low percentile (0.16): 0.02\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.11\n",
      "  hd_low percentile (0.75): 0.24\n",
      "  hd_low percentile (0.84): 0.32\n",
      "  hd_low percentile (0.95): 0.59\n",
      "  hd_low percentile (0.975): 0.81\n",
      "hd_high_mean (+/- std): 0.45 +/- 0.82\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.07\n",
      "  hd_high percentile (0.25): 0.09\n",
      "  hd_high percentile (0.5): 0.24\n",
      "  hd_high percentile (0.75): 0.51\n",
      "  hd_high percentile (0.84): 0.69\n",
      "  hd_high percentile (0.95): 1.35\n",
      "  hd_high percentile (0.975): 2.04\n",
      "mf_mean (+/- std): 0.41 +/- 0.3\n",
      "  mf percentile (0.025): 0.05\n",
      "  mf percentile (0.05): 0.07\n",
      "  mf percentile (0.16): 0.12\n",
      "  mf percentile (0.25): 0.16\n",
      "  mf percentile (0.5): 0.31\n",
      "  mf percentile (0.75): 0.61\n",
      "  mf percentile (0.84): 0.79\n",
      "  mf percentile (0.95): 0.99\n",
      "  mf percentile (0.975): 1.04\n",
      "mf_low_mean (+/- std): 0.52 +/- 0.33\n",
      "  mf_low percentile (0.025): 0.08\n",
      "  mf_low percentile (0.05): 0.1\n",
      "  mf_low percentile (0.16): 0.18\n",
      "  mf_low percentile (0.25): 0.23\n",
      "  mf_low percentile (0.5): 0.44\n",
      "  mf_low percentile (0.75): 0.85\n",
      "  mf_low percentile (0.84): 0.99\n",
      "  mf_low percentile (0.95): 1.0\n",
      "  mf_low percentile (0.975): 1.05\n",
      "mf_high_mean (+/- std): 0.31 +/- 0.23\n",
      "  mf_high percentile (0.025): 0.03\n",
      "  mf_high percentile (0.05): 0.05\n",
      "  mf_high percentile (0.16): 0.09\n",
      "  mf_high percentile (0.25): 0.12\n",
      "  mf_high percentile (0.5): 0.24\n",
      "  mf_high percentile (0.75): 0.46\n",
      "  mf_high percentile (0.84): 0.58\n",
      "  mf_high percentile (0.95): 0.75\n",
      "  mf_high percentile (0.975): 0.8\n",
      "\n",
      "\n",
      "hd_mean (+/- std): 0.35 +/- 0.58\n",
      "  hd percentile (0.025): 0.0\n",
      "  hd percentile (0.05): 0.0\n",
      "  hd percentile (0.16): 0.03\n",
      "  hd percentile (0.25): 0.05\n",
      "  hd percentile (0.5): 0.15\n",
      "  hd percentile (0.75): 0.38\n",
      "  hd percentile (0.84): 0.57\n",
      "  hd percentile (0.95): 1.51\n",
      "  hd percentile (0.975): 3.0\n",
      "hd_low_mean (+/- std): 0.21 +/- 0.31\n",
      "  hd_low percentile (0.025): 0\n",
      "  hd_low percentile (0.05): 0\n",
      "  hd_low percentile (0.16): 0.01\n",
      "  hd_low percentile (0.25): 0.03\n",
      "  hd_low percentile (0.5): 0.09\n",
      "  hd_low percentile (0.75): 0.25\n",
      "  hd_low percentile (0.84): 0.37\n",
      "  hd_low percentile (0.95): 0.9\n",
      "  hd_low percentile (0.975): 1.51\n",
      "hd_high_mean (+/- std): 0.62 +/- 1.35\n",
      "  hd_high percentile (0.025): 0.04\n",
      "  hd_high percentile (0.05): 0.04\n",
      "  hd_high percentile (0.16): 0.06\n",
      "  hd_high percentile (0.25): 0.08\n",
      "  hd_high percentile (0.5): 0.21\n",
      "  hd_high percentile (0.75): 0.52\n",
      "  hd_high percentile (0.84): 0.79\n",
      "  hd_high percentile (0.95): 2.38\n",
      "  hd_high percentile (0.975): 7.66\n",
      "mf_mean (+/- std): 0.63 +/- 0.46\n",
      "  mf percentile (0.025): 0.04\n",
      "  mf percentile (0.05): 0.05\n",
      "  mf percentile (0.16): 0.15\n",
      "  mf percentile (0.25): 0.23\n",
      "  mf percentile (0.5): 0.51\n",
      "  mf percentile (0.75): 1.0\n",
      "  mf percentile (0.84): 1.13\n",
      "  mf percentile (0.95): 1.45\n",
      "  mf percentile (0.975): 1.61\n",
      "mf_low_mean (+/- std): 0.73 +/- 0.45\n",
      "  mf_low percentile (0.025): 0.07\n",
      "  mf_low percentile (0.05): 0.09\n",
      "  mf_low percentile (0.16): 0.22\n",
      "  mf_low percentile (0.25): 0.33\n",
      "  mf_low percentile (0.5): 0.72\n",
      "  mf_low percentile (0.75): 1.03\n",
      "  mf_low percentile (0.84): 1.18\n",
      "  mf_low percentile (0.95): 1.48\n",
      "  mf_low percentile (0.975): 1.64\n",
      "mf_high_mean (+/- std): 0.51 +/- 0.42\n",
      "  mf_high percentile (0.025): 0.02\n",
      "  mf_high percentile (0.05): 0.03\n",
      "  mf_high percentile (0.16): 0.11\n",
      "  mf_high percentile (0.25): 0.17\n",
      "  mf_high percentile (0.5): 0.38\n",
      "  mf_high percentile (0.75): 0.77\n",
      "  mf_high percentile (0.84): 1.0\n",
      "  mf_high percentile (0.95): 1.32\n",
      "  mf_high percentile (0.975): 1.48\n"
     ]
    }
   ],
   "source": [
    "# Glaciers optimized\n",
    "overwrite = False\n",
    "rois = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14', '15', '16','17','18']\n",
    "# rois = ['15']\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [0.025, 0.05, 0.16, 0.25, 0.5, 0.75, 0.84, 0.95, 0.975]\n",
    "\n",
    "# Uncertainty dataframe and dictionary for bounds\n",
    "hd_uncertainty_fullfn = debris_prms.output_fp + 'hd_uncertainty_bnds-1std.csv'\n",
    "hd_uncertainty_df = pd.read_csv(hd_uncertainty_fullfn)\n",
    "hd_uncertainty_dict_low = dict(zip([int(np.round(x*100)) for x in hd_uncertainty_df['hd_m']], \n",
    "                                   list(hd_uncertainty_df['hd_bndlow_both'].values)))\n",
    "hd_uncertainty_dict_low[0] = 0\n",
    "hd_uncertainty_dict_low[1] = 0\n",
    "hd_uncertainty_dict_high = dict(zip([int(np.round(x*100)) for x in hd_uncertainty_df['hd_m']], \n",
    "                                   list(hd_uncertainty_df['hd_bndhigh_both'].values)))\n",
    "hd_uncertainty_dict_high[0] = hd_uncertainty_df.loc[0,'hd_bndhigh_both']\n",
    "hd_uncertainty_dict_high[1] = hd_uncertainty_df.loc[0,'hd_bndhigh_both']\n",
    "\n",
    "\n",
    "\n",
    "# Regional stats dataframe\n",
    "reg_stats_fullfn = debris_prms.output_fp + 'reg_stats_hd_mf.csv'\n",
    "reg_stats_cns = ['roi', 'dc_area_km2', 'dc_area_km2_lt_10cm', 'dc_area_km2_lt_50cm', 'dc_area_km2_lt_1m',\n",
    "                 'hd_mean', 'hd_std', \n",
    "                 'hd_025', 'hd_05', 'hd_16', 'hd_25', 'hd_med', 'hd_75', 'hd_84', 'hd_95', 'hd_975',\n",
    "                 'hd_low_mean', 'hd_low_std', \n",
    "                 'hd_low_025', 'hd_low_05', 'hd_low_16', 'hd_low_25', 'hd_low_med', 'hd_low_75', 'hd_low_84', 'hd_low_95', 'hd_low_975',\n",
    "                 'hd_high_mean', 'hd_high_std', \n",
    "                 'hd_high_025', 'hd_high_05', 'hd_high_16', 'hd_high_25', 'hd_high_med', 'hd_high_75', 'hd_high_84', 'hd_high_95', 'hd_high_975',\n",
    "                 'mf_mean', 'mf_std', \n",
    "                 'mf_025', 'mf_05', 'mf_16', 'mf_25', 'mf_med', 'mf_75', 'mf_84', 'mf_95', 'mf_975',\n",
    "                 'mf_low_mean', 'mf_low_std', \n",
    "                 'mf_low_025', 'mf_low_05', 'mf_low_16', 'mf_low_25', 'mf_low_med', 'mf_low_75', 'mf_low_84', 'mf_low_95', 'mf_low_975',\n",
    "                 'mf_high_mean', 'mf_high_std', \n",
    "                 'mf_high_025', 'mf_high_05', 'mf_high_16', 'mf_high_25', 'mf_high_med', 'mf_high_75', 'mf_high_84', 'mf_high_95', 'mf_high_975']\n",
    "reg_stats_df = pd.DataFrame(np.zeros((len(rois)+1,len(reg_stats_cns))), columns=reg_stats_cns)\n",
    "\n",
    "\n",
    "## ===== REGIONAL MELT FACTOR STATISTICS =====\n",
    "hd_list_all_global = []\n",
    "hd_list_all_low_global = []\n",
    "hd_list_all_high_global = []\n",
    "mf_list_all_global = []\n",
    "mf_list_all_low_global = []\n",
    "mf_list_all_high_global = []\n",
    "area_m2_list_all_global = []\n",
    "for nroi, roi in enumerate(rois):\n",
    "        \n",
    "    print('roi:', roi)\n",
    "    \n",
    "    # Load file if it already exists\n",
    "    list_fp = debris_prms.output_fp + 'pickle_datasets/'\n",
    "    if not os.path.exists(list_fp):\n",
    "        os.makedirs(list_fp)\n",
    "    hd_list_all_fullfn = list_fp + roi + '_hd_list_all.pkl'\n",
    "    mf_list_all_fullfn = list_fp + roi + '_mf_list_all.pkl'\n",
    "    area_m2_list_all_fullfn = list_fp + roi + '_area_m2_list_all.pkl'\n",
    "    \n",
    "\n",
    "    if os.path.exists(hd_list_all_fullfn.replace('.pkl','_low.pkl')) and not overwrite:\n",
    "        # Debris thickness\n",
    "        with open(hd_list_all_fullfn, 'rb') as f:\n",
    "            hd_list_all = pickle.load(f)\n",
    "        with open(hd_list_all_fullfn.replace('.pkl','_low.pkl'), 'rb') as f:\n",
    "            hd_list_all_low = pickle.load(f)\n",
    "        with open(hd_list_all_fullfn.replace('.pkl','_high.pkl'), 'rb') as f:\n",
    "            hd_list_all_high = pickle.load(f)\n",
    "        # Melt factor\n",
    "        with open(mf_list_all_fullfn, 'rb') as f:\n",
    "            mf_list_all = pickle.load(f)\n",
    "        with open(mf_list_all_fullfn.replace('.pkl','_low.pkl'), 'rb') as f:\n",
    "            mf_list_all_low = pickle.load(f)\n",
    "        with open(mf_list_all_fullfn.replace('.pkl','_high.pkl'), 'rb') as f:\n",
    "            mf_list_all_high = pickle.load(f)\n",
    "        # Area\n",
    "        with open(area_m2_list_all_fullfn, 'rb') as f:\n",
    "            area_m2_list_all = pickle.load(f)\n",
    "    else:\n",
    "        \n",
    "        rgiids = []\n",
    "        hd_fns = []\n",
    "        # Filepaths\n",
    "        if roi in ['13', '14', '15']:\n",
    "            hd_fp = debris_prms.output_fp + 'ts_tif/hd_tifs/HMA/'\n",
    "            hdopt_prms_fp = debris_prms.output_fp + 'hd_opt_prms/HMA/'\n",
    "        else:\n",
    "            hd_fp = debris_prms.output_fp + 'ts_tif/hd_tifs/' + roi + '/'\n",
    "            hdopt_prms_fp = debris_prms.output_fp + 'hd_opt_prms/' + roi + '/'\n",
    "        hd_fp_extrap = hd_fp + 'extrap/'\n",
    "        hdopt_prms_fp_extrap = hdopt_prms_fp + '/_extrap/'\n",
    "        mf_fp = hd_fp + 'meltfactor/'\n",
    "        mf_fp_extrap = hd_fp_extrap + 'meltfactor/'\n",
    "\n",
    "        # Glaciers optimized\n",
    "        glac_hd_fullfns = []\n",
    "        for i in os.listdir(hd_fp):\n",
    "            if i.endswith('hdts_m.tif'):\n",
    "                reg_str = str(int(i.split('.')[0])).zfill(2)\n",
    "                if reg_str == roi:\n",
    "                    hd_fns.append(i)\n",
    "                    rgiids.append(i.split('_')[0])\n",
    "\n",
    "        # Glaciers extrapolated\n",
    "        for i in os.listdir(hd_fp_extrap):\n",
    "            if i.endswith('hdts_m_extrap.tif'):\n",
    "                reg_str = str(int(i.split('.')[0])).zfill(2)\n",
    "                if reg_str == roi:\n",
    "                    hd_fns.append(i)\n",
    "                    rgiids.append(i.split('_')[0])\n",
    "\n",
    "        # Sorted files        \n",
    "        hd_fns = [x for _,x in sorted(zip(rgiids, hd_fns))]\n",
    "        rgiids = sorted(rgiids)     \n",
    "\n",
    "        main_glac_rgi = debris_prms.selectglaciersrgitable(rgiids)\n",
    "        main_glac_rgi['CenLon_360'] = main_glac_rgi['CenLon']\n",
    "        main_glac_rgi.loc[main_glac_rgi['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "            360 + main_glac_rgi.loc[main_glac_rgi['CenLon_360'] < 0, 'CenLon_360'])\n",
    "        main_glac_rgi['hd_fn'] = hd_fns\n",
    "        \n",
    "        hd_list_all = []\n",
    "        hd_list_all_low = []\n",
    "        hd_list_all_high = []\n",
    "        mf_list_all = []\n",
    "        mf_list_all_low = []\n",
    "        mf_list_all_high = []\n",
    "        area_m2_list_all = []\n",
    "        for nglac, glac_idx in enumerate(main_glac_rgi.index.values):\n",
    "#         for nglac, glac_idx in enumerate(main_glac_rgi.index.values[613:614]):\n",
    "            glac_str = main_glac_rgi.loc[glac_idx,'rgino_str']\n",
    "            rgiid = main_glac_rgi.loc[glac_idx,'RGIId']\n",
    "            region = glac_str.split('.')[0]\n",
    "\n",
    "            if int(region) < 10:\n",
    "                glac_str_noleadzero = str(int(glac_str.split('.')[0])) + '.' + glac_str.split('.')[1]\n",
    "            else:\n",
    "                glac_str_noleadzero = glac_str\n",
    "\n",
    "            if nglac%1000 == 0:\n",
    "#             if nglac%1 == 0:\n",
    "                print(nglac, glac_str)\n",
    "\n",
    "            # Create glacier feature from ice thickness raster\n",
    "            thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "            thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "\n",
    "            gf = create_glacfeat(thick_dir, thick_fn)\n",
    "\n",
    "            # =====FILENAMES =====\n",
    "            # Add the filenames\n",
    "            fn_dict = OrderedDict()\n",
    "            # DEM\n",
    "            z1_fp = debris_prms.oggm_fp + 'dems/RGI60-' + str(region.zfill(2)) + '/'\n",
    "            z1_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_dem.tif'\n",
    "            fn_dict['z1'] = z1_fp + z1_fn\n",
    "\n",
    "            # Debris thickness and melt factors\n",
    "            hd_fn = main_glac_rgi.loc[glac_idx, 'hd_fn']\n",
    "            if '_extrap' not in hd_fn:\n",
    "                hd_fullfn = hd_fp + hd_fn\n",
    "                mf_fullfn = mf_fp + hd_fn.replace('hdts_m', 'meltfactor')\n",
    "                hdopt_prms_fullfn = hdopt_prms_fp + glac_str_noleadzero + '_hdopt_prms.csv'\n",
    "            else:\n",
    "                hd_fullfn = hd_fp_extrap + hd_fn\n",
    "                mf_fullfn = mf_fp_extrap + hd_fn.replace('hdts_m', 'meltfactor')\n",
    "                hdopt_prms_fullfn = hdopt_prms_fp_extrap + glac_str + '_hdopt_prms_extrap.csv'\n",
    "                \n",
    "            fn_dict['debris_thick_ts'] = hd_fullfn\n",
    "            fn_dict['meltfactor_ts'] = mf_fullfn\n",
    "\n",
    "            # Ice thickness\n",
    "            thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "            thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "            fn_dict['ice_thick'] = thick_dir + thick_fn\n",
    "\n",
    "            # ===== PROCESS THE DATA =====\n",
    "            #Expand extent to include buffered region around glacier polygon\n",
    "            warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=debris_prms.buff_dist)\n",
    "            if verbose:\n",
    "                print(\"Expanding extent\")\n",
    "                print(gf.glac_geom_extent)\n",
    "                print(warp_extent)\n",
    "                print(gf.aea_srs)\n",
    "\n",
    "            #Warp everything to common res/extent/proj\n",
    "            z1_gt = gdal.Open(fn_dict['z1']).GetGeoTransform()\n",
    "            z1_res = np.min([z1_gt[1], -z1_gt[5]])\n",
    "            # resampling algorithm\n",
    "            r_resampling = 'cubic'\n",
    "            ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, extent=warp_extent, \n",
    "                                               t_srs=gf.aea_srs, verbose=verbose, r=r_resampling)\n",
    "            ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "            gf.ds_dict = ds_dict\n",
    "\n",
    "            if verbose:\n",
    "                print(ds_list)\n",
    "                print(fn_dict.keys())\n",
    "\n",
    "            glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "            gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "            \n",
    "            # Debris thickness values of 0 are masked (use meltfactor mask instead)\n",
    "            gf.meltfactor_ts = np.ma.array(iolib.ds_getma(ds_dict['meltfactor_ts']), mask=glac_geom_mask)\n",
    "            gf.debris_thick_ts = np.ma.array(iolib.ds_getma(ds_dict['debris_thick_ts']), mask=glac_geom_mask)\n",
    "            gf.debris_thick_ts = np.ma.array(gf.debris_thick_ts.data, mask=gf.meltfactor_ts.mask)\n",
    "            \n",
    "#             # Melt factors are masked so only calculate over areas with debris > 0\n",
    "#             gf.debris_thick_ts = np.ma.array(iolib.ds_getma(ds_dict['debris_thick_ts']), mask=glac_geom_mask)\n",
    "#             gf.meltfactor_ts = np.ma.array(iolib.ds_getma(ds_dict['meltfactor_ts']), mask=glac_geom_mask)       \n",
    "#             gf.meltfactor_ts = np.ma.array(gf.meltfactor_ts.data, mask=gf.debris_thick_ts.mask)\n",
    "            \n",
    "            gf.res = geolib.get_res(ds_dict['z1'])\n",
    "\n",
    "            if verbose:\n",
    "                print('\\n\\n# z1 pixels:', gf.z1.count(), '\\n')\n",
    "                \n",
    "            \n",
    "\n",
    "            # ===== PLOTS =====\n",
    "            show_plots = False\n",
    "            if debug and show_plots:\n",
    "                # DEM\n",
    "                var_full2plot = gf.z1.copy()\n",
    "                clim = malib.calcperc(var_full2plot, (2,98))\n",
    "                plot_array(var_full2plot, clim, [glac_str + ' DEM'], 'inferno', 'elev (masl)', close_fig=False)\n",
    "                # Debris thickness\n",
    "                var_full2plot = gf.debris_thick_ts.copy()\n",
    "                clim = (0,1)\n",
    "                plot_array(var_full2plot, clim, [gf.glacnum + ' hd (from ts)'], 'inferno', 'hd (m)', \n",
    "                           close_fig=False)\n",
    "                # Melt factor\n",
    "                var_full2plot = gf.meltfactor_ts.copy()\n",
    "                clim = (0,1)\n",
    "                plot_array(var_full2plot, clim, [gf.glacnum + ' meltfactor'], 'inferno', 'mf (-)',\n",
    "                           close_fig=False)\n",
    "    #             # Surface temperature\n",
    "    #             var_full2plot = gf.ts.copy()\n",
    "    #             clim = malib.calcperc(var_full2plot, (2,98))\n",
    "    #             plot_array(var_full2plot, clim, [glac_str + ' Ts'], 'inferno', 'ts (degC)', close_fig=False)\n",
    "\n",
    "            # Get list of values\n",
    "            hd_list = list(gf.debris_thick_ts.compressed())\n",
    "            mf_list = list(gf.meltfactor_ts.compressed())\n",
    "            \n",
    "            # remove nan values\n",
    "            hd_list = [0 if np.isnan(x) else x for x in hd_list]\n",
    "            \n",
    "            if len(hd_list) > 0:\n",
    "                # Remove nan values\n",
    "                hd_array_nonan = np.array(hd_list)\n",
    "                nan_idx_list = [x[0] for x in list(np.argwhere(np.isnan(hd_array_nonan)))]\n",
    "                if len(nan_idx_list) > 0:\n",
    "                    hd_list = [y for x,y in enumerate(hd_list) if x not in nan_idx_list]\n",
    "                    mf_list = [y for x,y in enumerate(mf_list) if x not in nan_idx_list]\n",
    "\n",
    "                assert len(hd_list) == len(mf_list), 'hd_list and mf_list differ; NEED TO MASK THESE VALUES OR RE-PROCESS'\n",
    "                rounding_err = 1e-6\n",
    "                assert np.max(hd_list) <= debris_prms.hd_max + rounding_err and np.min(hd_list) >= -rounding_err, 'hd outside of bounds' # rounding error may give -1e-12 for some values\n",
    "                assert np.min(mf_list) >= -rounding_err, 'negative melt factor' \n",
    "                assert np.max(mf_list) <= 10, 'melt factor greater than 10!'\n",
    "\n",
    "                pixel_m2 = abs(gf.res[0] * gf.res[1])\n",
    "                area_m2_list = [pixel_m2] * len(hd_list)\n",
    "\n",
    "                # Append to existing\n",
    "                hd_list_all.extend(hd_list)\n",
    "                mf_list_all.extend(mf_list)\n",
    "                area_m2_list_all.extend(area_m2_list)\n",
    "                \n",
    "                \n",
    "                # ----- Uncertainty: hd_list and mf_list -----\n",
    "                # Uncertainty for lower and upper bounds\n",
    "                hd_list_low = [hd_uncertainty_dict_low[x] for x in list(np.round(np.array(hd_list)*100,0).astype(int))]\n",
    "                hd_list_high = [hd_uncertainty_dict_high[x] for x in list(np.round(np.array(hd_list)*100,0).astype(int))]\n",
    "\n",
    "                # Optimized parameters for melt factor uncertainties\n",
    "                df_opt = pd.read_csv(hdopt_prms_fullfn)\n",
    "                melt_2cm = df_opt.loc[0,'melt_mwea_2cm']\n",
    "                melt_cleanice = df_opt.loc[0,'melt_mwea_clean']\n",
    "                func_coeff = [df_opt.loc[0,'b0'], df_opt.loc[0,'k']]\n",
    "\n",
    "                # Melt factor (lower bound)\n",
    "                mf_array_low = melt_fromdebris_func(np.array(hd_list_low), func_coeff[0], func_coeff[1]) / melt_cleanice\n",
    "                # limit melt rates to modeled 2 cm rate\n",
    "                mf_array_low[mf_array_low > melt_2cm / melt_cleanice] = melt_2cm / melt_cleanice\n",
    "                # Linearly interpolate between 0 cm and 2 cm for the melt rate\n",
    "                def meltfactor_0to2cm_adjustment(mf, melt_clean, melt_2cm, hd):\n",
    "                    \"\"\" Linearly interpolate melt factors between 0 and 2 cm \n",
    "                        based on clean ice and 2 cm sub-debris melt \"\"\"\n",
    "                    mf = np.nan_to_num(mf,0)\n",
    "                    mf[(hd >= 0) & (hd < 0.02)] = (\n",
    "                        1 + hd[(hd >= 0) & (hd < 0.02)] / 0.02 * (melt_2cm - melt_clean) / melt_clean)\n",
    "                    return mf\n",
    "                mf_array_low = meltfactor_0to2cm_adjustment(mf_array_low, melt_cleanice, melt_2cm, np.array(hd_list_low))\n",
    "\n",
    "                # Melt factor (lower bound)\n",
    "                mf_array_high = melt_fromdebris_func(np.array(hd_list_high), func_coeff[0], func_coeff[1]) / melt_cleanice\n",
    "                mf_array_high[mf_array_high > melt_2cm / melt_cleanice] = melt_2cm / melt_cleanice\n",
    "                mf_array_high = meltfactor_0to2cm_adjustment(mf_array_high, melt_cleanice, melt_2cm, np.array(hd_list_high))\n",
    "\n",
    "                # Append lists\n",
    "                hd_list_all_low.extend(hd_list_low)\n",
    "                hd_list_all_high.extend(hd_list_high)\n",
    "                mf_list_all_low.extend(list(mf_array_low))\n",
    "                mf_list_all_high.extend(list(mf_array_high))\n",
    "\n",
    "        # ===== EXPORT LISTS =====\n",
    "        pickle_data(hd_list_all_fullfn, hd_list_all)\n",
    "        pickle_data(hd_list_all_fullfn.replace('.pkl','_low.pkl'), hd_list_all_low)\n",
    "        pickle_data(hd_list_all_fullfn.replace('.pkl','_high.pkl'), hd_list_all_high)\n",
    "        pickle_data(mf_list_all_fullfn, mf_list_all)\n",
    "        pickle_data(mf_list_all_fullfn.replace('.pkl','_low.pkl'), mf_list_all_low)\n",
    "        pickle_data(mf_list_all_fullfn.replace('.pkl','_high.pkl'), mf_list_all_high)\n",
    "        pickle_data(area_m2_list_all_fullfn, area_m2_list_all)\n",
    "        \n",
    "    \n",
    "    # Aggregate global data\n",
    "    hd_list_all_global.extend(hd_list_all)\n",
    "    hd_list_all_low_global.extend(hd_list_all_low)\n",
    "    hd_list_all_high_global.extend(hd_list_all_high)\n",
    "    mf_list_all_global.extend(mf_list_all)\n",
    "    mf_list_all_low_global.extend(mf_list_all_low)\n",
    "    mf_list_all_high_global.extend(mf_list_all_high)\n",
    "    area_m2_list_all_global.extend(area_m2_list_all)\n",
    "    \n",
    "    \n",
    "    def reg_stats_weighted_fromlist(list_all, area_m2_list_all, percentiles, print_name=None):\n",
    "        \"\"\" Compute weighted regional stats based on list of debris thickness or melt factors and area\"\"\"\n",
    "        # Sort for weighted statistics\n",
    "        sorted_area_m2 = [x for _,x in sorted(zip(list_all, area_m2_list_all))]\n",
    "        sorted_list = sorted(list_all)\n",
    "        \n",
    "        # Regional statistics\n",
    "        list_mean, list_std = weighted_avg_and_std(sorted_list, weights=sorted_area_m2)\n",
    "        if print_name is not None:\n",
    "            print(print_name + '_mean (+/- std): ' + str(np.round(list_mean,2)) + ' +/- ' + str(np.round(list_std,2)))\n",
    "        reg_stats_values = []\n",
    "        reg_stats_values.append(list_mean)\n",
    "        reg_stats_values.append(list_std)\n",
    "        for percentile in percentiles:\n",
    "            value_percentile = weighted_percentile(sorted_list, sorted_area_m2, percentile)\n",
    "            reg_stats_values.append(value_percentile)\n",
    "            print('  ' + print_name + ' percentile (' + str(percentile) + '): ' +  str(np.round(value_percentile,2)))\n",
    "        return reg_stats_values\n",
    "    \n",
    "    # Compute regional statistics\n",
    "    reg_stats_values = [roi, np.sum(area_m2_list_all) / 1e6]\n",
    "    # ----- Debris-covered area for various thresholds -----\n",
    "    hd_list_all_array = np.array(hd_list_all)\n",
    "    area_km2_list_all_array = np.array(area_m2_list_all) / 1e6\n",
    "    for hd_threshold in [0.1, 0.5, 1.]:\n",
    "        hd_idxs = np.where(hd_list_all_array < hd_threshold)[0]\n",
    "        if len(hd_idxs) > 0:\n",
    "            dc_area_km2_lt_threshold = area_km2_list_all_array[hd_idxs].sum()\n",
    "        else:\n",
    "            dc_area_km2_lt_threshold = 0 \n",
    "        reg_stats_values.extend([dc_area_km2_lt_threshold])\n",
    "    # ----- Debris thickness -----\n",
    "    reg_stats_subset = reg_stats_weighted_fromlist(hd_list_all, area_m2_list_all, percentiles, print_name='hd')\n",
    "    reg_stats_values.extend(reg_stats_subset)\n",
    "    # Debris thickness (low uncertainty)\n",
    "    reg_stats_subset = reg_stats_weighted_fromlist(hd_list_all_low, area_m2_list_all, percentiles, print_name='hd_low')\n",
    "    reg_stats_values.extend(reg_stats_subset)\n",
    "    # Debris thickness (high uncertainty)\n",
    "    reg_stats_subset = reg_stats_weighted_fromlist(hd_list_all_high, area_m2_list_all, percentiles, print_name='hd_high')\n",
    "    reg_stats_values.extend(reg_stats_subset)\n",
    "    # ----- Melt factor -----\n",
    "    reg_stats_subset = reg_stats_weighted_fromlist(mf_list_all, area_m2_list_all, percentiles, print_name='mf')\n",
    "    reg_stats_values.extend(reg_stats_subset)\n",
    "    # Melt factor (low uncertainty)\n",
    "    reg_stats_subset = reg_stats_weighted_fromlist(mf_list_all_low, area_m2_list_all, percentiles, print_name='mf_low')\n",
    "    reg_stats_values.extend(reg_stats_subset)\n",
    "    # Melt factor\n",
    "    reg_stats_subset = reg_stats_weighted_fromlist(mf_list_all_high, area_m2_list_all, percentiles, print_name='mf_high')\n",
    "    reg_stats_values.extend(reg_stats_subset)\n",
    "    \n",
    "    # Record regional stats\n",
    "    reg_stats_df.loc[nroi,:] = reg_stats_values\n",
    "    \n",
    "#     print(reg_stats_values)\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "# GLOBAL STATISTICS\n",
    "nroi += 1\n",
    "hd_list_all = hd_list_all_global\n",
    "hd_list_all_low = hd_list_all_low_global\n",
    "hd_list_all_high = hd_list_all_high_global\n",
    "mf_list_all = mf_list_all_global\n",
    "mf_list_all_low = mf_list_all_low_global\n",
    "mf_list_all_high = mf_list_all_high_global\n",
    "area_m2_list_all = area_m2_list_all_global\n",
    "\n",
    "# Compute regional statistics\n",
    "reg_stats_values = ['all', np.sum(area_m2_list_all) / 1e6]\n",
    "# ----- Debris-covered area for various thresholds -----\n",
    "hd_list_all_array = np.array(hd_list_all)\n",
    "area_km2_list_all_array = np.array(area_m2_list_all) / 1e6\n",
    "for hd_threshold in [0.1, 0.5, 1.]:\n",
    "    hd_idxs = np.where(hd_list_all_array < hd_threshold)[0]\n",
    "    if len(hd_idxs) > 0:\n",
    "        dc_area_km2_lt_threshold = area_km2_list_all_array[hd_idxs].sum()\n",
    "    else:\n",
    "        dc_area_km2_lt_threshold = 0 \n",
    "    reg_stats_values.extend([dc_area_km2_lt_threshold])\n",
    "# ----- Debris thickness -----\n",
    "reg_stats_subset = reg_stats_weighted_fromlist(hd_list_all, area_m2_list_all, percentiles, print_name='hd')\n",
    "reg_stats_values.extend(reg_stats_subset)\n",
    "# Debris thickness (low uncertainty)\n",
    "reg_stats_subset = reg_stats_weighted_fromlist(hd_list_all_low, area_m2_list_all, percentiles, print_name='hd_low')\n",
    "reg_stats_values.extend(reg_stats_subset)\n",
    "# Debris thickness (high uncertainty)\n",
    "reg_stats_subset = reg_stats_weighted_fromlist(hd_list_all_high, area_m2_list_all, percentiles, print_name='hd_high')\n",
    "reg_stats_values.extend(reg_stats_subset)\n",
    "# ----- Melt factor -----\n",
    "reg_stats_subset = reg_stats_weighted_fromlist(mf_list_all, area_m2_list_all, percentiles, print_name='mf')\n",
    "reg_stats_values.extend(reg_stats_subset)\n",
    "# Melt factor (low uncertainty)\n",
    "reg_stats_subset = reg_stats_weighted_fromlist(mf_list_all_low, area_m2_list_all, percentiles, print_name='mf_low')\n",
    "reg_stats_values.extend(reg_stats_subset)\n",
    "# Melt factor\n",
    "reg_stats_subset = reg_stats_weighted_fromlist(mf_list_all_high, area_m2_list_all, percentiles, print_name='mf_high')\n",
    "reg_stats_values.extend(reg_stats_subset)\n",
    "\n",
    "reg_stats_df.loc[nroi,:] = reg_stats_values\n",
    "\n",
    "# ==== Export regional stats =====\n",
    "reg_stats_df.to_csv(reg_stats_fullfn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Melt factor stats\n",
    "#     mf_mean, mf_std = weighted_avg_and_std(mf_list_all, weights=area_m2_list_all)\n",
    "#     print('hd_mean (+/- std): ' + str(np.round(mf_mean,2)) + ' +/- ' + str(np.round(mf_std,2)))\n",
    "\n",
    "#     percentiles = [0.025, 0.05, 0.16, 0.25, 0.5, 0.75, 0.84, 0.95, 0.975]\n",
    "#     for percentile in percentiles:\n",
    "#         value_percentile = weighted_percentile(sorted_mf, sorted_area_m2_4mf)\n",
    "#         print('  mf percentile (' + str(percentile) + '): ' +  str(np.round(value_percentile,2)))\n",
    "# batman = []\n",
    "# for nweight, weight in enumerate(area_m2_list_all):\n",
    "#     batman.extend([hd_list_all[nweight]] * int(weight))\n",
    "# print(len(batman))\n",
    "# np.median(batman)\n",
    "# print(np.median(batman), np.mean(batman))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the region of debris-covered data\n",
    "rois = ['01','02','03','04','05','06','07','08','09','10','11','12','HMA','16','17','18']\n",
    "for roi in rois:\n",
    "    dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[roi])\n",
    "    dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "\n",
    "    dc_rgiids = [str(int(x.split('-')[1].split('.')[0])) + '.' + x.split('-')[1].split('.')[1] for x in dc_shp.RGIId]\n",
    "    \n",
    "    mb_bin_all_fp = debris_prms.output_fp + 'mb_bins_all/csv/' + roi + '/'\n",
    "    dc_rgiids_wdata = []\n",
    "    for i in os.listdir(mb_bin_all_fp):\n",
    "        glac_str = i.split('_')[0]\n",
    "        if glac_str in dc_rgiids:\n",
    "            dc_rgiids_wdata.append(glac_str)\n",
    "            \n",
    "    # Select glaciers\n",
    "    main_glac_rgi_dc = debris_prms.selectglaciersrgitable(dc_rgiids)\n",
    "    main_glac_rgi_dc_wdata = debris_prms.selectglaciersrgitable(dc_rgiids_wdata)\n",
    "\n",
    "    # Add debris stats to area\n",
    "    dc_areaperc_dict = dict(zip(dc_shp.RGIId.values,dc_shp['DC_Area__1'].values))\n",
    "    dc_area_dict = dict(zip(dc_shp.RGIId.values,dc_shp['DC_Area_v2'].values))\n",
    "    \n",
    "    main_glac_rgi_dc['DC_Area_%'] = main_glac_rgi_dc.RGIId.map(dc_areaperc_dict).fillna(0)\n",
    "    main_glac_rgi_dc_wdata['DC_Area_%'] = main_glac_rgi_dc_wdata.RGIId.map(dc_areaperc_dict).fillna(0)\n",
    "    main_glac_rgi_dc['DC_Area_v2'] = main_glac_rgi_dc['Area'] * main_glac_rgi_dc['DC_Area_%'] / 100\n",
    "    main_glac_rgi_dc_wdata['DC_Area_v2'] = main_glac_rgi_dc_wdata['Area'] * main_glac_rgi_dc_wdata['DC_Area_%'] / 100\n",
    "\n",
    "    # Subset of glaciers\n",
    "    main_glac_rgi_dc_gt2km2 = (\n",
    "        main_glac_rgi_dc[((main_glac_rgi_dc['DC_Area_%'] > debris_prms.dc_percarea_threshold) |\n",
    "                          (main_glac_rgi_dc['DC_Area_v2'] / 1e6 > debris_prms.dc_area_threshold))\n",
    "                         & (main_glac_rgi_dc['Area'] > debris_prms.min_glac_area)].copy())\n",
    "    \n",
    "    # Statistics of interest\n",
    "    print('\\n', roi + ': ', main_glac_rgi_dc.shape[0], 'glaciers -',\n",
    "          str(np.round(main_glac_rgi_dc['DC_Area_v2'].sum(),1)), 'km2')  \n",
    "    \n",
    "    print('  (> 2 km2): ', main_glac_rgi_dc_gt2km2.shape[0], 'glaciers -',\n",
    "          str(np.round(main_glac_rgi_dc_gt2km2['DC_Area_v2'].sum(),1)), 'km2')  \n",
    "    \n",
    "    print('  (w data): ', main_glac_rgi_dc_wdata.shape[0], 'glaciers -',\n",
    "          str(np.round(main_glac_rgi_dc_wdata['DC_Area_v2'].sum(),1)), 'km2\\n\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "DONE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nDONE\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rgiid: 13.43232\n",
      "  total dc_area (km2): 20.95\n",
      "  dc_area (mf < 0.1): 3.53 (16.8%)\n",
      "  dc_area (mf < 0.5): 16.38 (78.2%)\n",
      "  dc_area (mf > 1): 2.27 (10.8%)\n",
      "  mf_min: 0.03 mf_max: 1.26\n",
      "rgiid: 15.03473\n",
      "  total dc_area (km2): 19.09\n",
      "  dc_area (mf < 0.1): 6.57 (34.4%)\n",
      "  dc_area (mf < 0.5): 16.1 (84.4%)\n",
      "  dc_area (mf > 1): 1.67 (8.7%)\n",
      "  mf_min: 0.03 mf_max: 1.31\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics for individual glaciers\n",
    "# rgiids = ['1.15645', '11.03005', '14.06794']\n",
    "rgiids = ['13.43232','15.03473']\n",
    "\n",
    "\n",
    "## ===== REGIONAL MELT FACTOR STATISTICS =====\n",
    "for nglacier, rgiid in enumerate(rgiids):\n",
    "        \n",
    "    print('rgiid:', rgiid)\n",
    "    \n",
    "    roi = rgiid.split('.')[0].zfill(2)\n",
    "    region = roi\n",
    "    glacno = rgiid.split('.')[1]\n",
    "    glac_str = rgiid\n",
    "    glac_str_noleadzero = rgiid\n",
    "    \n",
    "    rgiids = []\n",
    "    hd_fns = []\n",
    "    # Filepaths\n",
    "    if roi in ['13', '14', '15']:\n",
    "        hd_fp = debris_prms.output_fp + 'ts_tif/hd_tifs/HMA/'\n",
    "    else:\n",
    "        hd_fp = debris_prms.output_fp + 'ts_tif/hd_tifs/' + roi + '/'\n",
    "    hd_fp_extrap = hd_fp + 'extrap/'\n",
    "    mf_fp = hd_fp + 'meltfactor/'\n",
    "    mf_fp_extrap = hd_fp_extrap + 'meltfactor/'\n",
    "\n",
    "    # Glaciers optimized\n",
    "    if os.path.exists(hd_fp + rgiid + '_hdts_m.tif'):\n",
    "        hd_fullfn = hd_fp + rgiid + '_hdts_m.tif'\n",
    "        mf_fullfn = mf_fp + rgiid + '_meltfactor.tif'\n",
    "    elif os.path.exists(hd_fp_extrap + rgiid + '_hdts_m_extrap.tif'):\n",
    "        hd_fullfn = hd_fp_extrap + rgiid + '_hdts_m_extrap.tif'\n",
    "        mf_fullfn = mf_fp_extrap + rgiid + '_meltfactor_extrap.tif'\n",
    "    \n",
    "    # Create glacier feature from ice thickness raster\n",
    "    thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "    thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "\n",
    "    gf = create_glacfeat(thick_dir, thick_fn)\n",
    "\n",
    "    # =====FILENAMES =====\n",
    "    # Add the filenames\n",
    "    fn_dict = OrderedDict()\n",
    "    # DEM\n",
    "    z1_fp = debris_prms.oggm_fp + 'dems/RGI60-' + str(region.zfill(2)) + '/'\n",
    "    z1_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_dem.tif'\n",
    "    fn_dict['z1'] = z1_fp + z1_fn\n",
    "\n",
    "    # Debris thickness and melt factors\n",
    "    fn_dict['debris_thick_ts'] = hd_fullfn\n",
    "    fn_dict['meltfactor_ts'] = mf_fullfn\n",
    "\n",
    "    # Ice thickness\n",
    "    thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "    thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "    fn_dict['ice_thick'] = thick_dir + thick_fn\n",
    "\n",
    "    # ===== PROCESS THE DATA =====\n",
    "    #Expand extent to include buffered region around glacier polygon\n",
    "    warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=debris_prms.buff_dist)\n",
    "    if verbose:\n",
    "        print(\"Expanding extent\")\n",
    "        print(gf.glac_geom_extent)\n",
    "        print(warp_extent)\n",
    "        print(gf.aea_srs)\n",
    "\n",
    "    #Warp everything to common res/extent/proj\n",
    "    z1_gt = gdal.Open(fn_dict['z1']).GetGeoTransform()\n",
    "    z1_res = np.min([z1_gt[1], -z1_gt[5]])\n",
    "    # resampling algorithm\n",
    "    r_resampling = 'cubic'\n",
    "    ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, extent=warp_extent, \n",
    "                                       t_srs=gf.aea_srs, verbose=verbose, r=r_resampling)\n",
    "    ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "    gf.ds_dict = ds_dict\n",
    "\n",
    "    if verbose:\n",
    "        print(ds_list)\n",
    "        print(fn_dict.keys())\n",
    "\n",
    "    glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "    gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "\n",
    "    # Debris thickness values of 0 are masked (use meltfactor mask instead)\n",
    "    gf.meltfactor_ts = np.ma.array(iolib.ds_getma(ds_dict['meltfactor_ts']), mask=glac_geom_mask)\n",
    "    gf.debris_thick_ts = np.ma.array(iolib.ds_getma(ds_dict['debris_thick_ts']), mask=glac_geom_mask)\n",
    "    gf.debris_thick_ts = np.ma.array(gf.debris_thick_ts.data, mask=gf.meltfactor_ts.mask)\n",
    "\n",
    "    gf.res = geolib.get_res(ds_dict['z1'])\n",
    "\n",
    "    if verbose:\n",
    "        print('\\n\\n# z1 pixels:', gf.z1.count(), '\\n')\n",
    "\n",
    "\n",
    "    # ===== PLOTS =====\n",
    "    show_plots = False\n",
    "    debug = False\n",
    "    if debug and show_plots:\n",
    "        # DEM\n",
    "        var_full2plot = gf.z1.copy()\n",
    "        clim = malib.calcperc(var_full2plot, (2,98))\n",
    "        plot_array(var_full2plot, clim, [glac_str + ' DEM'], 'inferno', 'elev (masl)', close_fig=False)\n",
    "        # Debris thickness\n",
    "        var_full2plot = gf.debris_thick_ts.copy()\n",
    "        clim = (0,1)\n",
    "        plot_array(var_full2plot, clim, [gf.glacnum + ' hd (from ts)'], 'inferno', 'hd (m)', \n",
    "                   close_fig=False)\n",
    "        # Melt factor\n",
    "        var_full2plot = gf.meltfactor_ts.copy()\n",
    "        clim = (0,1)\n",
    "        plot_array(var_full2plot, clim, [gf.glacnum + ' meltfactor'], 'inferno', 'mf (-)',\n",
    "                   close_fig=False)\n",
    "\n",
    "    # Get list of values\n",
    "    hd_list = list(gf.debris_thick_ts.compressed())\n",
    "    mf_list = list(gf.meltfactor_ts.compressed())\n",
    "\n",
    "    # remove nan values\n",
    "    hd_list = [0 if np.isnan(x) else x for x in hd_list]\n",
    "\n",
    "    if len(hd_list) > 0:\n",
    "        # Remove nan values\n",
    "        hd_array_nonan = np.array(hd_list)\n",
    "        nan_idx_list = [x[0] for x in list(np.argwhere(np.isnan(hd_array_nonan)))]\n",
    "        if len(nan_idx_list) > 0:\n",
    "            hd_list = [y for x,y in enumerate(hd_list) if x not in nan_idx_list]\n",
    "            mf_list = [y for x,y in enumerate(mf_list) if x not in nan_idx_list]\n",
    "\n",
    "        assert len(hd_list) == len(mf_list), 'hd_list and mf_list differ; NEED TO MASK THESE VALUES OR RE-PROCESS'\n",
    "        rounding_err = 1e-6\n",
    "        assert np.max(hd_list) <= debris_prms.hd_max + rounding_err and np.min(hd_list) >= -rounding_err, 'hd outside of bounds' # rounding error may give -1e-12 for some values\n",
    "        assert np.min(mf_list) >= -rounding_err, 'negative melt factor' \n",
    "        assert np.max(mf_list) <= 10, 'melt factor greater than 10!'\n",
    "\n",
    "        pixel_m2 = abs(gf.res[0] * gf.res[1])\n",
    "        area_m2_list = [pixel_m2] * len(hd_list)\n",
    "        \n",
    "        mf_array = np.array(mf_list)\n",
    "        area_km2_array = np.array(area_m2_list) / 1e6\n",
    "        dc_area_km2 = area_km2_array.sum()\n",
    "        print('  total dc_area (km2):', np.round(dc_area_km2,2))\n",
    "        mf_idxs = np.where(mf_array < 0.1)[0]\n",
    "        print('  dc_area (mf < 0.1):', \n",
    "              np.round(area_km2_array[mf_idxs].sum(),2), \n",
    "              '(' + str(np.round(area_km2_array[mf_idxs].sum() / dc_area_km2 * 100,1)) + '%)')\n",
    "        mf_idxs = np.where(mf_array < 0.5)[0]\n",
    "        print('  dc_area (mf < 0.5):', \n",
    "              np.round(area_km2_array[mf_idxs].sum(),2), \n",
    "              '(' + str(np.round(area_km2_array[mf_idxs].sum() / dc_area_km2 * 100,1)) + '%)')\n",
    "        mf_idxs = np.where(mf_array > 1)[0]\n",
    "        print('  dc_area (mf > 1):', \n",
    "              np.round(area_km2_array[mf_idxs].sum(),2), \n",
    "              '(' + str(np.round(area_km2_array[mf_idxs].sum() / dc_area_km2 * 100,1)) + '%)')\n",
    "        print('  mf_min:', np.round(mf_array.min(),2), 'mf_max:', np.round(mf_array.max(),2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6834 glaciers in region 1 are included in this model run: ['00006', '00010', '00012', '00013', '00016', '00017', '00020', '00021', '00022', '00023', '00025', '00027', '00029', '00030', '00032', '00033', '00035', '00036', '00037', '00038', '00040', '00041', '00042', '00044', '00045', '00046', '00068', '00080', '00112', '00118', '00130', '00135', '00138', '00140', '00148', '00151', '00152', '00154', '00159', '00170', '00176', '00187', '00189', '00191', '00194', '00196', '00202', '00224', '00225', '00232'] and more\n",
      "This study is focusing on 6834 glaciers in region [1]\n",
      "1109 glaciers in region 1 are included in this model run: ['00006', '00013', '00027', '00033', '00035', '00037', '00038', '00040', '00041', '00042', '00044', '00045', '00046', '00140', '00148', '00187', '00242', '00312', '00336', '00348', '00351', '00399', '00409', '00426', '00434', '00436', '00537', '00544', '00556', '00557', '00558', '00560', '00561', '00565', '00566', '00569', '00570', '00571', '00572', '00574', '00576', '00578', '00579', '00581', '00582', '00584', '00600', '00660', '00670', '00675'] and more\n",
      "This study is focusing on 1109 glaciers in region [1]\n",
      "01 91.0\n",
      "3313 glaciers in region 2 are included in this model run: ['00006', '00016', '00018', '00020', '00039', '00079', '00097', '00098', '00118', '00126', '00134', '00147', '00157', '00173', '00174', '00180', '00208', '00212', '00226', '00227', '00242', '00252', '00255', '00256', '00259', '00280', '00288', '00289', '00291', '00296', '00305', '00317', '00330', '00336', '00343', '00346', '00347', '00354', '00366', '00377', '00378', '00381', '00403', '00404', '00406', '00411', '00412', '00424', '00440', '00451'] and more\n",
      "This study is focusing on 3313 glaciers in region [2]\n",
      "219 glaciers in region 2 are included in this model run: ['00280', '00737', '00914', '01104', '01152', '01158', '01161', '01290', '01291', '01297', '01339', '01397', '01441', '01654', '01665', '01685', '01727', '01811', '01812', '01922', '01923', '02107', '02348', '02360', '02386', '02432', '02526', '02527', '02533', '02550', '02551', '02616', '02636', '02686', '02745', '02747', '02752', '02784', '02857', '02894', '02897', '02947', '02948', '02966', '03099', '03102', '03157', '03520', '03578', '03581'] and more\n",
      "This study is focusing on 219 glaciers in region [2]\n",
      "02 34.0\n",
      "1965 glaciers in region 3 are included in this model run: ['00093', '00094', '00095', '00096', '00097', '00098', '00099', '00100', '00102', '00103', '00104', '00105', '00106', '00107', '00108', '00109', '00110', '00113', '00114', '00115', '00116', '00117', '00118', '00120', '00123', '00124', '00125', '00126', '00128', '00129', '00130', '00131', '00132', '00133', '00134', '00135', '00136', '00137', '00139', '00140', '00141', '00142', '00143', '00144', '00145', '00146', '00147', '00148', '00150', '00151'] and more\n",
      "This study is focusing on 1965 glaciers in region [3]\n",
      "297 glaciers in region 3 are included in this model run: ['00113', '00115', '00123', '00136', '00237', '00240', '00412', '00527', '00691', '00704', '00708', '00716', '00717', '00718', '00730', '00828', '00832', '00878', '00915', '00921', '00922', '00923', '00928', '00937', '00938', '00945', '00979', '00982', '00984', '00986', '00987', '00994', '00995', '01005', '01175', '01176', '01177', '01178', '01180', '01188', '01192', '01193', '01210', '01211', '01212', '01215', '01218', '01267', '01325', '01341'] and more\n",
      "This study is focusing on 297 glaciers in region [3]\n",
      "03 66.0\n",
      "2972 glaciers in region 4 are included in this model run: ['00002', '00003', '00004', '00005', '00007', '00008', '00009', '00012', '00013', '00015', '00016', '00018', '00019', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00036', '00037', '00038', '00039', '00040', '00041', '00042', '00043', '00045', '00046', '00047', '00050', '00051', '00052', '00053', '00054', '00056', '00057', '00058', '00059', '00060', '00061', '00062'] and more\n",
      "This study is focusing on 2972 glaciers in region [4]\n",
      "409 glaciers in region 4 are included in this model run: ['00004', '00005', '00015', '00022', '00027', '00029', '00030', '00032', '00047', '00050', '00051', '00052', '00053', '00054', '00056', '00061', '00086', '00089', '00094', '00096', '00170', '00172', '00177', '00181', '00183', '00184', '00188', '00194', '00196', '00215', '00231', '00232', '00263', '00268', '00270', '00274', '00278', '00289', '00329', '00339', '00344', '00366', '00509', '00698', '00726', '00870', '00896', '00907', '00909', '00910'] and more\n",
      "This study is focusing on 409 glaciers in region [4]\n",
      "04 57.0\n",
      "5363 glaciers in region 5 are included in this model run: ['00024', '00035', '00046', '00056', '00058', '00062', '00066', '00068', '00076', '00086', '00096', '00099', '00101', '00102', '00105', '00108', '00109', '00115', '00117', '00120', '00121', '00122', '00124', '00126', '00129', '00139', '00143', '00151', '00154', '00156', '00157', '00161', '00164', '00168', '00169', '00181', '00184', '00188', '00191', '00196', '00200', '00202', '00207', '00210', '00211', '00217', '00222', '00226', '00244', '00247'] and more\n",
      "This study is focusing on 5363 glaciers in region [5]\n",
      "663 glaciers in region 5 are included in this model run: ['00115', '00181', '00184', '00258', '00270', '00275', '00318', '00319', '00323', '00334', '00335', '00336', '00337', '00342', '00400', '00421', '00445', '00446', '00451', '00459', '00460', '00522', '00530', '00789', '00790', '00793', '00794', '00800', '00801', '00817', '00839', '00859', '00879', '00904', '00938', '01224', '01355', '01383', '01403', '01441', '01452', '01456', '01706', '01780', '02398', '02521', '02536', '02651', '02918', '03019'] and more\n",
      "This study is focusing on 663 glaciers in region [5]\n",
      "05 76.0\n",
      "190 glaciers in region 6 are included in this model run: ['00001', '00007', '00008', '00014', '00015', '00017', '00022', '00036', '00039', '00041', '00048', '00050', '00058', '00064', '00067', '00078', '00080', '00084', '00085', '00111', '00117', '00118', '00119', '00127', '00150', '00166', '00168', '00169', '00170', '00171', '00172', '00177', '00187', '00190', '00193', '00196', '00202', '00206', '00207', '00208', '00211', '00212', '00213', '00214', '00215', '00216', '00218', '00219', '00220', '00224'] and more\n",
      "This study is focusing on 190 glaciers in region [6]\n",
      "60 glaciers in region 6 are included in this model run: ['00008', '00017', '00041', '00202', '00208', '00220', '00232', '00233', '00234', '00235', '00236', '00237', '00238', '00286', '00291', '00303', '00309', '00310', '00317', '00321', '00324', '00326', '00328', '00329', '00332', '00336', '00339', '00340', '00341', '00342', '00343', '00344', '00345', '00346', '00347', '00359', '00365', '00377', '00406', '00407', '00416', '00423', '00424', '00427', '00429', '00443', '00445', '00465', '00466', '00468'] and more\n",
      "This study is focusing on 60 glaciers in region [6]\n",
      "06 93.0\n",
      "866 glaciers in region 7 are included in this model run: ['00001', '00005', '00006', '00008', '00010', '00020', '00021', '00023', '00030', '00031', '00034', '00035', '00036', '00038', '00039', '00041', '00043', '00045', '00050', '00064', '00066', '00067', '00068', '00069', '00070', '00071', '00073', '00086', '00087', '00088', '00089', '00093', '00095', '00097', '00098', '00100', '00102', '00103', '00105', '00106', '00112', '00113', '00114', '00118', '00119', '00120', '00123', '00124', '00127', '00128'] and more\n",
      "This study is focusing on 866 glaciers in region [7]\n",
      "333 glaciers in region 7 are included in this model run: ['00041', '00093', '00118', '00151', '00161', '00166', '00175', '00191', '00197', '00203', '00205', '00221', '00223', '00226', '00227', '00230', '00238', '00240', '00249', '00253', '00256', '00265', '00272', '00273', '00274', '00275', '00277', '00283', '00295', '00296', '00299', '00300', '00302', '00311', '00312', '00313', '00317', '00318', '00319', '00323', '00324', '00325', '00342', '00349', '00351', '00352', '00360', '00361', '00362', '00363'] and more\n",
      "This study is focusing on 333 glaciers in region [7]\n",
      "07 93.0\n",
      "621 glaciers in region 8 are included in this model run: ['00001', '00002', '00004', '00005', '00006', '00007', '00008', '00009', '00012', '00013', '00014', '00015', '00016', '00020', '00021', '00024', '00025', '00026', '00028', '00029', '00030', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042', '00043', '00044', '00045', '00046', '00047', '00048', '00049', '00050', '00051', '00052', '00053', '00054', '00056', '00057', '00058', '00059', '00060', '00061'] and more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This study is focusing on 621 glaciers in region [8]\n",
      "25 glaciers in region 8 are included in this model run: ['00006', '00015', '00024', '00040', '00072', '00075', '00090', '00105', '00126', '00137', '00199', '00213', '00245', '00767', '01482', '01483', '01485', '01486', '01558', '01607', '01623', '01650', '01658', '02256', '02392'] and more\n",
      "This study is focusing on 25 glaciers in region [8]\n",
      "08 15.0\n",
      "527 glaciers in region 9 are included in this model run: ['00014', '00016', '00025', '00027', '00028', '00029', '00031', '00033', '00034', '00035', '00038', '00040', '00051', '00053', '00055', '00056', '00057', '00058', '00060', '00061', '00062', '00064', '00065', '00066', '00067', '00069', '00070', '00071', '00072', '00073', '00077', '00079', '00080', '00081', '00083', '00086', '00087', '00088', '00090', '00091', '00092', '00093', '00094', '00095', '00096', '00097', '00099', '00101', '00102', '00103'] and more\n",
      "This study is focusing on 527 glaciers in region [9]\n",
      "69 glaciers in region 9 are included in this model run: ['00014', '00033', '00051', '00053', '00055', '00056', '00060', '00071', '00077', '00086', '00120', '00123', '00129', '00132', '00134', '00138', '00153', '00197', '00201', '00207', '00215', '00230', '00244', '00246', '00248', '00254', '00255', '00275', '00277', '00302', '00303', '00307', '00312', '00329', '00343', '00352', '00359', '00362', '00367', '00369', '00392', '00393', '00394', '00441', '00478', '00484', '00524', '00551', '00552', '00572'] and more\n",
      "This study is focusing on 69 glaciers in region [9]\n",
      "09 49.0\n",
      "341 glaciers in region 10 are included in this model run: ['00001', '00002', '00005', '00006', '00007', '00008', '00016', '00018', '00019', '00021', '00022', '00024', '00025', '00036', '00042', '00043', '00044', '00046', '00048', '00049', '00050', '00051', '00052', '00054', '00056', '00058', '00059', '00060', '00061', '00063', '00064', '00065', '00066', '00067', '00068', '00070', '00071', '00072', '00074', '00075', '00077', '00078', '00079', '00080', '00081', '00082', '00083', '00084', '00085', '00086'] and more\n",
      "This study is focusing on 341 glaciers in region [10]\n",
      "21 glaciers in region 10 are included in this model run: ['00001', '00002', '00005', '00006', '01106', '01114', '01120', '01729', '01730', '01989', '02127', '03488', '03752', '03876', '03878', '04017', '04019', '04051', '04162', '04856', '05151'] and more\n",
      "This study is focusing on 21 glaciers in region [10]\n",
      "10 55.0\n",
      "2919 glaciers in region 11 are included in this model run: ['00001', '00002', '00003', '00004', '00005', '00006', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00018', '00019', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00030', '00031', '00034', '00037', '00038', '00039', '00040', '00041', '00042', '00043', '00046', '00047', '00048', '00049', '00050', '00051', '00053', '00054', '00055', '00056', '00060', '00062', '00063', '00065', '00066', '00067', '00068'] and more\n",
      "This study is focusing on 2919 glaciers in region [11]\n",
      "156 glaciers in region 11 are included in this model run: ['00002', '00047', '00054', '00068', '00106', '00110', '00116', '00135', '00141', '00190', '00199', '00233', '00278', '00376', '00415', '00459', '00469', '00487', '00524', '00541', '00597', '00719', '00781', '00797', '00830', '00846', '00871', '00886', '00887', '00897', '00918', '00929', '00932', '00943', '00945', '00950', '00957', '00958', '01144', '01187', '01193', '01246', '01275', '01296', '01328', '01346', '01450', '01478', '01509', '01550'] and more\n",
      "This study is focusing on 156 glaciers in region [11]\n",
      "11 57.0\n",
      "1130 glaciers in region 12 are included in this model run: ['00002', '00004', '00005', '00006', '00007', '00008', '00010', '00011', '00012', '00013', '00014', '00016', '00018', '00019', '00021', '00023', '00024', '00026', '00031', '00032', '00034', '00036', '00037', '00038', '00040', '00041', '00044', '00045', '00047', '00049', '00050', '00051', '00052', '00053', '00057', '00059', '00061', '00062', '00063', '00064', '00065', '00066', '00067', '00068', '00069', '00073', '00074', '00075', '00079', '00080'] and more\n",
      "This study is focusing on 1130 glaciers in region [12]\n",
      "102 glaciers in region 12 are included in this model run: ['00004', '00014', '00031', '00034', '00064', '00083', '00089', '00115', '00130', '00164', '00170', '00187', '00193', '00222', '00231', '00255', '00259', '00260', '00294', '00298', '00320', '00325', '00336', '00355', '00374', '00375', '00426', '00431', '00454', '00479', '00486', '00490', '00494', '00496', '00521', '00531', '00535', '00552', '00564', '00577', '00611', '00613', '00639', '00669', '00686', '00699', '00743', '00748', '00763', '00769'] and more\n",
      "This study is focusing on 102 glaciers in region [12]\n",
      "12 41.0\n",
      "8874 glaciers in region 13 are included in this model run: ['00067', '00080', '00093', '00137', '00175', '00188', '00190', '00198', '00199', '00200', '00202', '00203', '00209', '00210', '00211', '00217', '00218', '00221', '00222', '00223', '00226', '00228', '00233', '00235', '00236', '00240', '00246', '00248', '00250', '00299', '00335', '00345', '00358', '00386', '00391', '00394', '00399', '00400', '00402', '00413', '00420', '00500', '00502', '00503', '00505', '00507', '00508', '00515', '00516', '00517'] and more\n",
      "This study is focusing on 8874 glaciers in region [13]\n",
      "1090 glaciers in region 13 are included in this model run: ['00604', '00611', '00643', '00713', '00757', '00761', '00763', '00777', '00788', '00809', '00830', '00834', '00838', '00880', '00884', '00885', '00891', '00905', '00906', '00940', '00949', '00951', '00954', '00956', '00964', '00965', '00967', '00972', '00982', '00995', '00997', '00999', '01019', '01022', '01023', '01027', '01038', '01044', '01045', '01050', '01098', '01099', '01113', '01124', '01129', '01136', '01144', '01145', '01148', '01150'] and more\n",
      "This study is focusing on 1090 glaciers in region [13]\n",
      "13 72.0\n",
      "5873 glaciers in region 14 are included in this model run: ['00005', '00018', '00020', '00026', '00028', '00029', '00032', '00033', '00036', '00043', '00056', '00057', '00063', '00065', '00072', '00075', '00079', '00097', '00101', '00104', '00122', '00127', '00131', '00142', '00145', '00146', '00154', '00155', '00163', '00213', '00219', '00222', '00225', '00243', '00251', '00271', '00287', '00288', '00323', '00332', '00342', '00346', '00347', '00350', '00352', '00353', '00363', '00366', '00367', '00370'] and more\n",
      "This study is focusing on 5873 glaciers in region [14]\n",
      "1042 glaciers in region 14 are included in this model run: ['00005', '00018', '00032', '00036', '00043', '00057', '00072', '00104', '00145', '00163', '00222', '00287', '00353', '00363', '00471', '00543', '00548', '00555', '00595', '00700', '00722', '00742', '00764', '00767', '00796', '00805', '00850', '00891', '00899', '00952', '01001', '01022', '01070', '01075', '01165', '01191', '01206', '01226', '01228', '01244', '01285', '01361', '01379', '01391', '01400', '01409', '01425', '01454', '01474', '01489'] and more\n",
      "This study is focusing on 1042 glaciers in region [14]\n",
      "14 82.0\n",
      "5584 glaciers in region 15 are included in this model run: ['00001', '00007', '00008', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00037', '00038', '00039', '00040', '00042', '00043', '00044', '00045', '00047', '00051', '00052', '00053', '00054', '00055', '00057', '00058', '00060', '00061', '00062', '00065', '00066', '00071', '00072', '00073', '00075', '00076', '00077', '00078', '00079'] and more\n",
      "This study is focusing on 5584 glaciers in region [15]\n",
      "826 glaciers in region 15 are included in this model run: ['00026', '00055', '00057', '00186', '00232', '00233', '00234', '00355', '00356', '00368', '00379', '00399', '00406', '00423', '00475', '00503', '00612', '00617', '00621', '00655', '00835', '00850', '00868', '00869', '00872', '00880', '00881', '00885', '00894', '00898', '00899', '00909', '00910', '00911', '00920', '00957', '00996', '01004', '01024', '01030', '01031', '01032', '01062', '01077', '01078', '01087', '01089', '01094', '01096', '01098'] and more\n",
      "This study is focusing on 826 glaciers in region [15]\n",
      "15 78.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433 glaciers in region 16 are included in this model run: ['00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00014', '00015', '00018', '00019', '00020', '00021', '00022', '00023', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042', '00043', '00044', '00045', '00046', '00047', '00048', '00049', '00050', '00051', '00052', '00054', '00056'] and more\n",
      "This study is focusing on 1433 glaciers in region [16]\n",
      "209 glaciers in region 16 are included in this model run: ['00080', '00141', '00163', '00173', '00176', '00177', '00205', '00213', '00214', '00216', '00228', '00244', '00248', '00256', '00261', '00274', '00285', '00287', '00288', '00289', '00299', '00331', '00332', '00337', '00360', '00361', '00362', '00363', '00366', '00368', '00370', '00372', '00373', '00410', '00413', '00417', '00427', '00428', '00433', '00485', '00486', '00493', '00496', '00500', '00516', '00540', '00543', '00560', '00566', '00582'] and more\n",
      "This study is focusing on 209 glaciers in region [16]\n",
      "16 46.0\n",
      "6074 glaciers in region 17 are included in this model run: ['00001', '00008', '00009', '00011', '00013', '00014', '00015', '00016', '00021', '00022', '00023', '00024', '00029', '00031', '00032', '00055', '00064', '00065', '00066', '00067', '00068', '00070', '00074', '00080', '00081', '00083', '00095', '00102', '00122', '00134', '00136', '00141', '00144', '00148', '00172', '00271', '00312', '00367', '00368', '00396', '00412', '00421', '00424', '00426', '00456', '00466', '00467', '00468', '00469', '00471'] and more\n",
      "This study is focusing on 6074 glaciers in region [17]\n",
      "598 glaciers in region 17 are included in this model run: ['00023', '00080', '00141', '00172', '00466', '00516', '01019', '01100', '01101', '01108', '01112', '01123', '01128', '01218', '01236', '01253', '01421', '01429', '01448', '01495', '01506', '01554', '01638', '01687', '01762', '01879', '01917', '01921', '01940', '01970', '01972', '01974', '02025', '02035', '02071', '02265', '02427', '02504', '02519', '02531', '02547', '02600', '02617', '02642', '02665', '02666', '02671', '02674', '02685', '02687'] and more\n",
      "This study is focusing on 598 glaciers in region [17]\n",
      "17 60.0\n",
      "1011 glaciers in region 18 are included in this model run: ['00002', '00004', '00009', '00011', '00013', '00019', '00020', '00021', '00024', '00025', '00028', '00029', '00030', '00031', '00032', '00034', '00035', '00036', '00037', '00038', '00040', '00041', '00042', '00044', '00045', '00046', '00047', '00048', '00049', '00050', '00051', '00052', '00054', '00055', '00056', '00057', '00058', '00059', '00062', '00063', '00065', '00066', '00067', '00069', '00070', '00071', '00072', '00073', '00074', '00076'] and more\n",
      "This study is focusing on 1011 glaciers in region [18]\n",
      "43 glaciers in region 18 are included in this model run: ['00171', '00179', '00569', '00631', '00661', '00686', '00707', '00716', '00718', '00815', '00853', '00891', '00947', '00996', '01018', '01130', '01307', '01852', '01889', '01958', '01959', '02210', '02230', '02257', '02270', '02276', '02298', '02342', '02436', '02450', '02472', '02499', '02502', '02504', '02505', '02508', '03066', '03078', '03156', '03167', '03181', '03191', '03209'] and more\n",
      "This study is focusing on 43 glaciers in region [18]\n",
      "18 53.0\n"
     ]
    }
   ],
   "source": [
    "# Summary of data that has elevation change and velocity data\n",
    "rois = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18']\n",
    "# rois = ['15']\n",
    "\n",
    "output_cns = ['roi', 'dc_km2_wdata', 'dc_km2_total','mb_vel_perc']\n",
    "output_df = pd.DataFrame(np.zeros((len(rois), len(output_cns))), columns=output_cns)\n",
    "for nroi, roi in enumerate(rois):    \n",
    "    if roi in ['13','14','15']:\n",
    "        roi_4dict = 'HMA'\n",
    "    else:\n",
    "        roi_4dict = roi\n",
    "    \n",
    "    dhdt_vel_df = pd.read_csv(debris_prms.output_fp + 'dhdt_vel_fns/' + roi_4dict + '-dhdt_vel_fns.csv')\n",
    "    dhdt_vel_df['O1Region'] = [x.split('-')[1].split('.')[0] for x in dhdt_vel_df.RGIId.values]\n",
    "    \n",
    "    dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[roi_4dict])\n",
    "    dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "    \n",
    "    if roi in ['13','14','15']:\n",
    "        dhdt_vel_df = dhdt_vel_df[dhdt_vel_df.O1Region == roi]\n",
    "        dc_shp = dc_shp[dc_shp.O1Region == roi]\n",
    "\n",
    "    dc_rgiids = [str(int(x.split('-')[1].split('.')[0])) + '.' + x.split('-')[1].split('.')[1] for x in dc_shp.RGIId]\n",
    "    dhdt_vel_df_rgiids = [str(int(x.split('-')[1].split('.')[0])) + '.' + x.split('-')[1].split('.')[1] \n",
    "                          for x in dhdt_vel_df.RGIId]\n",
    "            \n",
    "    # Select glaciers\n",
    "    main_glac_rgi_dc = debris_prms.selectglaciersrgitable(dc_rgiids)\n",
    "    main_glac_rgi_wdata = debris_prms.selectglaciersrgitable(dhdt_vel_df_rgiids)\n",
    "\n",
    "    # Add debris stats to area\n",
    "    dc_areaperc_dict = dict(zip(dc_shp.RGIId.values,dc_shp['DC_Area__1'].values))\n",
    "    dc_area_dict = dict(zip(dc_shp.RGIId.values,dc_shp['DC_Area_v2'].values))\n",
    "    \n",
    "    main_glac_rgi_dc['DC_Area_%'] = main_glac_rgi_dc.RGIId.map(dc_areaperc_dict).fillna(0)\n",
    "    main_glac_rgi_dc['DC_Area_v2'] = main_glac_rgi_dc['Area'] * main_glac_rgi_dc['DC_Area_%'] / 100\n",
    "    main_glac_rgi_wdata['DC_Area_%'] = main_glac_rgi_wdata.RGIId.map(dc_areaperc_dict).fillna(0)\n",
    "    main_glac_rgi_wdata['DC_Area_v2'] = main_glac_rgi_wdata['Area'] * main_glac_rgi_wdata['DC_Area_%'] / 100\n",
    "    \n",
    "    \n",
    "    # Record data\n",
    "    dc_km2_wdata = main_glac_rgi_wdata['DC_Area_v2'].sum()\n",
    "    dc_km2_total = main_glac_rgi_dc['DC_Area_v2'].sum()\n",
    "    both_data_perc =  dc_km2_wdata / dc_km2_total * 100\n",
    "    \n",
    "    print(roi, np.round(both_data_perc))\n",
    "    output_df.loc[nroi,:] = [roi, dc_km2_wdata, dc_km2_total, both_data_perc]\n",
    "    \n",
    "output_df.to_csv(debris_prms.output_fp + 'dhdt_vel_data_percent_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6834 glaciers in region 1 are included in this model run: ['00006', '00010', '00012', '00013', '00016', '00017', '00020', '00021', '00022', '00023', '00025', '00027', '00029', '00030', '00032', '00033', '00035', '00036', '00037', '00038', '00040', '00041', '00042', '00044', '00045', '00046', '00068', '00080', '00112', '00118', '00130', '00135', '00138', '00140', '00148', '00151', '00152', '00154', '00159', '00170', '00176', '00187', '00189', '00191', '00194', '00196', '00202', '00224', '00225', '00232'] and more\n",
      "This study is focusing on 6834 glaciers in region [1]\n",
      "6959.984815399999 75552.992\n",
      "01 ALASKA (19.5), ARCTICDEM (56.7), SRTM (23.8)\n",
      "3313 glaciers in region 2 are included in this model run: ['00006', '00016', '00018', '00020', '00039', '00079', '00097', '00098', '00118', '00126', '00134', '00147', '00157', '00173', '00174', '00180', '00208', '00212', '00226', '00227', '00242', '00252', '00255', '00256', '00259', '00280', '00288', '00289', '00291', '00296', '00305', '00317', '00330', '00336', '00343', '00346', '00347', '00354', '00366', '00377', '00378', '00381', '00403', '00404', '00406', '00411', '00412', '00424', '00440', '00451'] and more\n",
      "This study is focusing on 3313 glaciers in region [2]\n",
      "448.79842611 8602.24\n",
      "02 SRTM (71.5), DEM3 (7.8), ARCTICDEM (18.8), ALASKA (1.9)\n",
      "1965 glaciers in region 3 are included in this model run: ['00093', '00094', '00095', '00096', '00097', '00098', '00099', '00100', '00102', '00103', '00104', '00105', '00106', '00107', '00108', '00109', '00110', '00113', '00114', '00115', '00116', '00117', '00118', '00120', '00123', '00124', '00125', '00126', '00128', '00129', '00130', '00131', '00132', '00133', '00134', '00135', '00136', '00137', '00139', '00140', '00141', '00142', '00143', '00144', '00145', '00146', '00147', '00148', '00150', '00151'] and more\n",
      "This study is focusing on 1965 glaciers in region [3]\n",
      "875.77925036 91041.926\n",
      "03 ARCTICDEM (99.7), GIMP (0.1), DEM3 (0.2)\n",
      "2972 glaciers in region 4 are included in this model run: ['00002', '00003', '00004', '00005', '00007', '00008', '00009', '00012', '00013', '00015', '00016', '00018', '00019', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00036', '00037', '00038', '00039', '00040', '00041', '00042', '00043', '00045', '00046', '00047', '00050', '00051', '00052', '00053', '00054', '00056', '00057', '00058', '00059', '00060', '00061', '00062'] and more\n",
      "This study is focusing on 2972 glaciers in region [4]\n",
      "784.9426995 34337.185\n",
      "04 ARCTICDEM (99.2), DEM3 (0.7), SRTM (0.1)\n",
      "5363 glaciers in region 5 are included in this model run: ['00024', '00035', '00046', '00056', '00058', '00062', '00066', '00068', '00076', '00086', '00096', '00099', '00101', '00102', '00105', '00108', '00109', '00115', '00117', '00120', '00121', '00122', '00124', '00126', '00129', '00139', '00143', '00151', '00154', '00156', '00157', '00161', '00164', '00168', '00169', '00181', '00184', '00188', '00191', '00196', '00200', '00202', '00207', '00210', '00211', '00217', '00222', '00226', '00244', '00247'] and more\n",
      "This study is focusing on 5363 glaciers in region [5]\n",
      "2341.98767202 107549.10500000001\n",
      "05 ARCTICDEM (98.9), GIMP (1.1), SRTM (0.0)\n",
      "190 glaciers in region 6 are included in this model run: ['00001', '00007', '00008', '00014', '00015', '00017', '00022', '00036', '00039', '00041', '00048', '00050', '00058', '00064', '00067', '00078', '00080', '00084', '00085', '00111', '00117', '00118', '00119', '00127', '00150', '00166', '00168', '00169', '00170', '00171', '00172', '00177', '00187', '00190', '00193', '00196', '00202', '00206', '00207', '00208', '00211', '00212', '00213', '00214', '00215', '00216', '00218', '00219', '00220', '00224'] and more\n",
      "This study is focusing on 190 glaciers in region [6]\n",
      "309.35371315 10654.703\n",
      "06 ARCTICDEM (99.8), DEM3 (0.2)\n",
      "866 glaciers in region 7 are included in this model run: ['00001', '00005', '00006', '00008', '00010', '00020', '00021', '00023', '00030', '00031', '00034', '00035', '00036', '00038', '00039', '00041', '00043', '00045', '00050', '00064', '00066', '00067', '00068', '00069', '00070', '00071', '00073', '00086', '00087', '00088', '00089', '00093', '00095', '00097', '00098', '00100', '00102', '00103', '00105', '00106', '00112', '00113', '00114', '00118', '00119', '00120', '00123', '00124', '00127', '00128'] and more\n",
      "This study is focusing on 866 glaciers in region [7]\n",
      "433.4141277 23204.521\n",
      "07 ARCTICDEM (99.2), DEM3 (0.8)\n",
      "621 glaciers in region 8 are included in this model run: ['00001', '00002', '00004', '00005', '00006', '00007', '00008', '00009', '00012', '00013', '00014', '00015', '00016', '00020', '00021', '00024', '00025', '00026', '00028', '00029', '00030', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042', '00043', '00044', '00045', '00046', '00047', '00048', '00049', '00050', '00051', '00052', '00053', '00054', '00056', '00057', '00058', '00059', '00060', '00061'] and more\n",
      "This study is focusing on 621 glaciers in region [8]\n",
      "50.828578050000004 1477.5739999999998\n",
      "08 ARCTICDEM (92.8), DEM3 (6.8), SRTM (0.4)\n",
      "527 glaciers in region 9 are included in this model run: ['00014', '00016', '00025', '00027', '00028', '00029', '00031', '00033', '00034', '00035', '00038', '00040', '00051', '00053', '00055', '00056', '00057', '00058', '00060', '00061', '00062', '00064', '00065', '00066', '00067', '00069', '00070', '00071', '00072', '00073', '00077', '00079', '00080', '00081', '00083', '00086', '00087', '00088', '00090', '00091', '00092', '00093', '00094', '00095', '00096', '00097', '00099', '00101', '00102', '00103'] and more\n",
      "This study is focusing on 527 glaciers in region [9]\n",
      "157.53388054 32855.49\n",
      "09 ARCTICDEM (97.9), DEM3 (2.1)\n",
      "341 glaciers in region 10 are included in this model run: ['00001', '00002', '00005', '00006', '00007', '00008', '00016', '00018', '00019', '00021', '00022', '00024', '00025', '00036', '00042', '00043', '00044', '00046', '00048', '00049', '00050', '00051', '00052', '00054', '00056', '00058', '00059', '00060', '00061', '00063', '00064', '00065', '00066', '00067', '00068', '00070', '00071', '00072', '00074', '00075', '00077', '00078', '00079', '00080', '00081', '00082', '00083', '00084', '00085', '00086'] and more\n",
      "This study is focusing on 341 glaciers in region [10]\n",
      "51.65474388 768.1940000000001\n",
      "10 ARCTICDEM (45.4), DEM3 (0.7), SRTM (53.9)\n",
      "2919 glaciers in region 11 are included in this model run: ['00001', '00002', '00003', '00004', '00005', '00006', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00018', '00019', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00030', '00031', '00034', '00037', '00038', '00039', '00040', '00041', '00042', '00043', '00046', '00047', '00048', '00049', '00050', '00051', '00053', '00054', '00055', '00056', '00060', '00062', '00063', '00065', '00066', '00067', '00068'] and more\n",
      "This study is focusing on 2919 glaciers in region [11]\n",
      "220.17703253000002 2034.65\n",
      "11 SRTM (100.0)\n",
      "1130 glaciers in region 12 are included in this model run: ['00002', '00004', '00005', '00006', '00007', '00008', '00010', '00011', '00012', '00013', '00014', '00016', '00018', '00019', '00021', '00023', '00024', '00026', '00031', '00032', '00034', '00036', '00037', '00038', '00040', '00041', '00044', '00045', '00047', '00049', '00050', '00051', '00052', '00053', '00057', '00059', '00061', '00062', '00063', '00064', '00065', '00066', '00067', '00068', '00069', '00073', '00074', '00075', '00079', '00080'] and more\n",
      "This study is focusing on 1130 glaciers in region [12]\n",
      "305.05974005999997 1138.475\n",
      "12 SRTM (100.0)\n",
      "8874 glaciers in region 13 are included in this model run: ['00067', '00080', '00093', '00137', '00175', '00188', '00190', '00198', '00199', '00200', '00202', '00203', '00209', '00210', '00211', '00217', '00218', '00221', '00222', '00223', '00226', '00228', '00233', '00235', '00236', '00240', '00246', '00248', '00250', '00299', '00335', '00345', '00358', '00386', '00391', '00394', '00399', '00400', '00402', '00413', '00420', '00500', '00502', '00503', '00505', '00507', '00508', '00515', '00516', '00517'] and more\n",
      "This study is focusing on 8874 glaciers in region [13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499.2898779399998 27288.634000000002\n",
      "13 SRTM (100.0)\n",
      "5873 glaciers in region 14 are included in this model run: ['00005', '00018', '00020', '00026', '00028', '00029', '00032', '00033', '00036', '00043', '00056', '00057', '00063', '00065', '00072', '00075', '00079', '00097', '00101', '00104', '00122', '00127', '00131', '00142', '00145', '00146', '00154', '00155', '00163', '00213', '00219', '00222', '00225', '00243', '00251', '00271', '00287', '00288', '00323', '00332', '00342', '00346', '00347', '00350', '00352', '00353', '00363', '00366', '00367', '00370'] and more\n",
      "This study is focusing on 5873 glaciers in region [14]\n",
      "2918.4395827099997 25430.577\n",
      "14 SRTM (100.0)\n",
      "5584 glaciers in region 15 are included in this model run: ['00001', '00007', '00008', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00037', '00038', '00039', '00040', '00042', '00043', '00044', '00045', '00047', '00051', '00052', '00053', '00054', '00055', '00057', '00058', '00060', '00061', '00062', '00065', '00066', '00071', '00072', '00073', '00075', '00076', '00077', '00078', '00079'] and more\n",
      "This study is focusing on 5584 glaciers in region [15]\n",
      "2205.35545803 11992.116999999998\n",
      "15 SRTM (100.0)\n",
      "1433 glaciers in region 16 are included in this model run: ['00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00014', '00015', '00018', '00019', '00020', '00021', '00022', '00023', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042', '00043', '00044', '00045', '00046', '00047', '00048', '00049', '00050', '00051', '00052', '00054', '00056'] and more\n",
      "This study is focusing on 1433 glaciers in region [16]\n",
      "358.37956324000004 1761.1569999999997\n",
      "16 SRTM (100.0)\n",
      "6074 glaciers in region 17 are included in this model run: ['00001', '00008', '00009', '00011', '00013', '00014', '00015', '00016', '00021', '00022', '00023', '00024', '00029', '00031', '00032', '00055', '00064', '00065', '00066', '00067', '00068', '00070', '00074', '00080', '00081', '00083', '00095', '00102', '00122', '00134', '00136', '00141', '00144', '00148', '00172', '00271', '00312', '00367', '00368', '00396', '00412', '00421', '00424', '00426', '00456', '00466', '00467', '00468', '00469', '00471'] and more\n",
      "This study is focusing on 6074 glaciers in region [17]\n",
      "1889.73450137 25672.695000000003\n",
      "17 SRTM (100.0)\n",
      "1011 glaciers in region 18 are included in this model run: ['00002', '00004', '00009', '00011', '00013', '00019', '00020', '00021', '00024', '00025', '00028', '00029', '00030', '00031', '00032', '00034', '00035', '00036', '00037', '00038', '00040', '00041', '00042', '00044', '00045', '00046', '00047', '00048', '00049', '00050', '00051', '00052', '00054', '00055', '00056', '00057', '00058', '00059', '00062', '00063', '00065', '00066', '00067', '00069', '00070', '00071', '00072', '00073', '00074', '00076'] and more\n",
      "This study is focusing on 1011 glaciers in region [18]\n",
      "174.17691105 818.447\n",
      "18 SRTM (100.0)\n"
     ]
    }
   ],
   "source": [
    "# Summary DEMs used for each region\n",
    "rois = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18']\n",
    "# rois = ['15']\n",
    "\n",
    "output_cns = ['roi', 'dem sources']\n",
    "output_df = pd.DataFrame(np.zeros((len(rois), len(output_cns))), columns=output_cns)\n",
    "for nroi, roi in enumerate(rois):\n",
    "    if roi in ['13','14','15']:\n",
    "        roi_4dict = 'HMA'\n",
    "    else:\n",
    "        roi_4dict = roi\n",
    "    dc_shp = gpd.read_file(debris_prms.debriscover_fp + debris_prms.debriscover_fn_dict[roi_4dict])\n",
    "    dc_shp = dc_shp.sort_values(by=['RGIId'])\n",
    "    \n",
    "    if roi in ['13','14','15']:\n",
    "        dc_shp = dc_shp[dc_shp.O1Region == roi]\n",
    "\n",
    "    dc_rgiids = [str(int(x.split('-')[1].split('.')[0])) + '.' + x.split('-')[1].split('.')[1] for x in dc_shp.RGIId]\n",
    "            \n",
    "    # Select glaciers\n",
    "    main_glac_rgi_dc = debris_prms.selectglaciersrgitable(dc_rgiids)\n",
    "\n",
    "    # Add debris stats to area\n",
    "    dc_areaperc_dict = dict(zip(dc_shp.RGIId.values,dc_shp['DC_Area__1'].values))\n",
    "    dc_area_dict = dict(zip(dc_shp.RGIId.values,dc_shp['DC_Area_v2'].values))\n",
    "    \n",
    "    main_glac_rgi_dc['DC_Area_%'] = main_glac_rgi_dc.RGIId.map(dc_areaperc_dict).fillna(0)\n",
    "    main_glac_rgi_dc['DC_Area_v2'] = main_glac_rgi_dc['Area'] * main_glac_rgi_dc['DC_Area_%'] / 100\n",
    "    \n",
    "    # Load the DEM sources\n",
    "    dem_df_all = pd.read_csv(debris_prms.oggm_fp + 'statistics/RGI60-' + roi + '.csv')\n",
    "    dem_df_all = dem_df_all.sort_values('rgi_id')\n",
    "    dem_df_all.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    dem_idx_all = []\n",
    "    dem_rgiid_list = list(dem_df_all.rgi_id.values)\n",
    "    for rgiid in main_glac_rgi_dc.RGIId.values:\n",
    "    # for rgiid in main_glac_rgi_dc.RGIId.values[0:10]:\n",
    "        dem_idx = dem_rgiid_list.index(rgiid)\n",
    "        dem_idx_all.append(dem_idx)\n",
    "    \n",
    "    # Subset of sources for the region\n",
    "    dem_df_roi = dem_df_all.loc[dem_idx_all]\n",
    "    dem_df_roi.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    dem_df_roi['DC_Area_v2'] = main_glac_rgi_dc['DC_Area_v2']\n",
    "    dem_df_roi['Area'] = main_glac_rgi_dc['Area']\n",
    "    \n",
    "    unique_dems = list(dem_df_roi.dem_source.unique())\n",
    "    if np.nan in unique_dems:\n",
    "        unique_dems.remove(np.nan)\n",
    "    dc_area_total = main_glac_rgi_dc['DC_Area_v2'].sum()\n",
    "    area_total = main_glac_rgi_dc['Area'].sum()\n",
    "    \n",
    "    print(dc_area_total, area_total)\n",
    "    output_str = None\n",
    "    for dem in unique_dems:\n",
    "        dem_df_roi_subset = dem_df_roi[dem_df_roi['dem_source'] == dem]\n",
    "        dc_area_perc = dem_df_roi_subset.DC_Area_v2.sum() / dc_area_total * 100\n",
    "        if output_str is None:\n",
    "            output_str = dem + ' (' + str(np.round(dc_area_perc,1)) + ')'\n",
    "        else:\n",
    "            output_str += ', ' + dem + ' (' + str(np.round(dc_area_perc,1)) + ')'\n",
    "    \n",
    "    print(roi, output_str)\n",
    "    output_df.loc[nroi,:] = [roi, output_str]\n",
    "    \n",
    "output_df.to_csv(debris_prms.output_fp + 'ogggm_dem_source_table.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debris_thickness_global]",
   "language": "python",
   "name": "conda-env-debris_thickness_global-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
