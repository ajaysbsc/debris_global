{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "Estimate the uncertainty associated with the debris thickness and enhancement factors for each elevation bin\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from scipy import ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import median_absolute_deviation\n",
    "import xarray as xr\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "from pygeotools.lib import malib, warplib, geolib, iolib, timelib\n",
    "\n",
    "\n",
    "import debrisglobal.globaldebris_input as debris_prms\n",
    "from debrisglobal.glacfeat import GlacFeat, create_glacfeat\n",
    "from meltcurves import melt_fromdebris_func\n",
    "from meltcurves import debris_frommelt_func\n",
    "from spc_split_lists import split_list\n",
    "\n",
    "\n",
    "debug=True\n",
    "verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate a 3-panel plot for input arrays\n",
    "def plot_array(dem, clim=None, titles=None, cmap='inferno', label=None, overlay=None, fn=None, close_fig=True):\n",
    "    fig, ax = plt.subplots(1,1, sharex=True, sharey=True, figsize=(10,5))\n",
    "    alpha = 1.0\n",
    "    #Gray background\n",
    "    ax.set_facecolor('0.5')\n",
    "    #Force aspect ratio to match images\n",
    "    ax.set(aspect='equal')\n",
    "    #Turn off axes labels/ticks\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if titles is not None:\n",
    "        ax.set_title(titles[0])\n",
    "    #Plot background shaded relief map\n",
    "    if overlay is not None:\n",
    "        alpha = 0.7\n",
    "        ax.imshow(overlay, cmap='gray', clim=(1,255))\n",
    "    #Plot each array\n",
    "    im_list = [ax.imshow(dem, clim=clim, cmap=cmap, alpha=alpha)]\n",
    "    fig.tight_layout()\n",
    "    fig.colorbar(im_list[0], label=label, extend='both', shrink=0.5)\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn, bbox_inches='tight', pad_inches=0, dpi=150)\n",
    "    if close_fig:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roi: 12\n",
      "1129 glaciers in region 12 are included in this model run: ['00002', '00004', '00005', '00006', '00007', '00008', '00010', '00011', '00012', '00013', '00014', '00016', '00018', '00019', '00021', '00023', '00024', '00026', '00031', '00032', '00034', '00036', '00037', '00038', '00040', '00041', '00044', '00045', '00047', '00049', '00050', '00051', '00052', '00053', '00057', '00059', '00061', '00062', '00063', '00064', '00065', '00066', '00067', '00068', '00069', '00073', '00074', '00075', '00079', '00080'] and more\n",
      "This study is focusing on 1129 glaciers in region [12]\n",
      "0 12.00002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrounce/anaconda3/envs/debris_thickness_global/lib/python3.6/site-packages/numpy/ma/core.py:4008: RuntimeWarning: invalid value encountered in equal\n",
      "  check = compare(sdata, odata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 12.01639\n",
      "roi: 13\n",
      "8834 glaciers in region 13 are included in this model run: ['00067', '00080', '00093', '00137', '00175', '00188', '00190', '00198', '00199', '00200', '00202', '00203', '00209', '00210', '00211', '00217', '00218', '00221', '00222', '00223', '00226', '00228', '00233', '00235', '00236', '00240', '00246', '00248', '00250', '00299', '00335', '00345', '00358', '00386', '00391', '00394', '00399', '00400', '00402', '00413', '00420', '00500', '00502', '00503', '00505', '00507', '00508', '00515', '00516', '00517'] and more\n",
      "This study is focusing on 8834 glaciers in region [13]\n",
      "0 13.00067\n",
      "1000 13.02609\n",
      "2000 13.05927\n",
      "3000 13.09317\n",
      "4000 13.14815\n",
      "5000 13.19073\n",
      "6000 13.24347\n",
      "7000 13.28708\n",
      "8000 13.43528\n",
      "roi: 14\n",
      "5869 glaciers in region 14 are included in this model run: ['00005', '00018', '00020', '00026', '00028', '00029', '00032', '00033', '00036', '00043', '00056', '00057', '00063', '00065', '00072', '00075', '00079', '00097', '00101', '00104', '00122', '00127', '00131', '00142', '00145', '00146', '00154', '00155', '00163', '00213', '00219', '00222', '00225', '00243', '00251', '00271', '00287', '00288', '00323', '00332', '00342', '00346', '00347', '00350', '00352', '00353', '00363', '00366', '00367', '00370'] and more\n",
      "This study is focusing on 5869 glaciers in region [14]\n",
      "0 14.00005\n",
      "1000 14.06769\n",
      "2000 14.12301\n",
      "3000 14.15700\n",
      "4000 14.19374\n",
      "5000 14.23280\n",
      "roi: 15\n",
      "5295 glaciers in region 15 are included in this model run: ['00001', '00007', '00008', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00037', '00038', '00039', '00040', '00042', '00043', '00044', '00045', '00047', '00051', '00052', '00053', '00054', '00055', '00057', '00058', '00060', '00061', '00062', '00065', '00066', '00071', '00072', '00073', '00075', '00076', '00077', '00078', '00079'] and more\n",
      "This study is focusing on 5295 glaciers in region [15]\n",
      "0 15.00001\n",
      "1000 15.02762\n",
      "2000 15.04979\n",
      "3000 15.06807\n",
      "4000 15.09506\n",
      "5000 15.12638\n",
      "roi: 18\n",
      "1011 glaciers in region 18 are included in this model run: ['00002', '00004', '00009', '00011', '00013', '00019', '00020', '00021', '00024', '00025', '00028', '00029', '00030', '00031', '00032', '00034', '00035', '00036', '00037', '00038', '00040', '00041', '00042', '00044', '00045', '00046', '00047', '00048', '00049', '00050', '00051', '00052', '00054', '00055', '00056', '00057', '00058', '00059', '00062', '00063', '00065', '00066', '00067', '00069', '00070', '00071', '00072', '00073', '00074', '00076'] and more\n",
      "This study is focusing on 1011 glaciers in region [18]\n",
      "0 18.00002\n",
      "1000 18.03512\n"
     ]
    }
   ],
   "source": [
    "# Glaciers optimized\n",
    "overwrite = False\n",
    "# rois = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14', '15', '16','17','18']\n",
    "rois = ['12','13','14','15','18']\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [0.025, 0.05, 0.16, 0.25, 0.5, 0.75, 0.84, 0.95, 0.975]\n",
    "\n",
    "# Uncertainty dataframe and dictionary for bounds\n",
    "hd_uncertainty_fullfn = debris_prms.output_fp + 'hd_uncertainty_bnds_1std.csv'\n",
    "hd_uncertainty_df = pd.read_csv(hd_uncertainty_fullfn)\n",
    "hd_uncertainty_dict_low = dict(zip([int(np.round(x*100)) for x in hd_uncertainty_df['hd_m']], \n",
    "                                   list(hd_uncertainty_df['hd_bndlow_both'].values)))\n",
    "hd_uncertainty_dict_low[0] = 0\n",
    "hd_uncertainty_dict_low[1] = 0\n",
    "hd_uncertainty_dict_high = dict(zip([int(np.round(x*100)) for x in hd_uncertainty_df['hd_m']], \n",
    "                                   list(hd_uncertainty_df['hd_bndhigh_both'].values)))\n",
    "hd_uncertainty_dict_high[0] = hd_uncertainty_df.loc[0,'hd_bndhigh_both']\n",
    "hd_uncertainty_dict_high[1] = hd_uncertainty_df.loc[0,'hd_bndhigh_both']\n",
    "\n",
    "\n",
    "## ===== REGIONAL MELT FACTOR STATISTICS =====\n",
    "for nroi, roi in enumerate(rois):\n",
    "        \n",
    "    print('roi:', roi)\n",
    "\n",
    "    rgiids = []\n",
    "    hd_fns = []\n",
    "    # Filepaths\n",
    "    if roi in ['13', '14', '15']:\n",
    "        hd_fp = debris_prms.output_fp + 'ts_tif/hd_tifs/HMA/'\n",
    "        hdopt_prms_fp = debris_prms.output_fp + 'hd_opt_prms/HMA/'\n",
    "    else:\n",
    "        hd_fp = debris_prms.output_fp + 'ts_tif/hd_tifs/' + roi + '/'\n",
    "        hdopt_prms_fp = debris_prms.output_fp + 'hd_opt_prms/' + roi + '/'\n",
    "    hd_fp_extrap = hd_fp + 'extrap/'\n",
    "    hdopt_prms_fp_extrap = hdopt_prms_fp + '/_extrap/'\n",
    "    mf_fp = hd_fp + 'meltfactor/'\n",
    "    mf_fp_extrap = hd_fp_extrap + 'meltfactor/'\n",
    "\n",
    "    # Glaciers optimized\n",
    "    glac_hd_fullfns = []\n",
    "    for i in os.listdir(hd_fp):\n",
    "        if i.endswith('hdts_m.tif'):\n",
    "            reg_str = str(int(i.split('.')[0])).zfill(2)\n",
    "            if reg_str == roi:\n",
    "                hd_fns.append(i)\n",
    "                rgiids.append(i.split('_')[0])\n",
    "\n",
    "    # Glaciers extrapolated\n",
    "    for i in os.listdir(hd_fp_extrap):\n",
    "        if i.endswith('hdts_m_extrap.tif'):\n",
    "            reg_str = str(int(i.split('.')[0])).zfill(2)\n",
    "            if reg_str == roi:\n",
    "                hd_fns.append(i)\n",
    "                rgiids.append(i.split('_')[0])\n",
    "\n",
    "    # Sorted files        \n",
    "    hd_fns = [x for _,x in sorted(zip(rgiids, hd_fns))]\n",
    "    rgiids = sorted(rgiids)     \n",
    "\n",
    "    main_glac_rgi = debris_prms.selectglaciersrgitable(rgiids)\n",
    "    main_glac_rgi['CenLon_360'] = main_glac_rgi['CenLon']\n",
    "    main_glac_rgi.loc[main_glac_rgi['CenLon_360'] < 0, 'CenLon_360'] = (\n",
    "        360 + main_glac_rgi.loc[main_glac_rgi['CenLon_360'] < 0, 'CenLon_360'])\n",
    "    main_glac_rgi['hd_fn'] = hd_fns\n",
    "\n",
    "    for nglac, glac_idx in enumerate(main_glac_rgi.index.values):\n",
    "#     for nglac, glac_idx in enumerate(main_glac_rgi.index.values[0:1]):\n",
    "        glac_str = main_glac_rgi.loc[glac_idx,'rgino_str']\n",
    "        rgiid = main_glac_rgi.loc[glac_idx,'RGIId']\n",
    "        region = glac_str.split('.')[0]\n",
    "\n",
    "        if int(region) < 10:\n",
    "            glac_str_noleadzero = str(int(glac_str.split('.')[0])) + '.' + glac_str.split('.')[1]\n",
    "        else:\n",
    "            glac_str_noleadzero = glac_str\n",
    "\n",
    "        if nglac%1000 == 0:\n",
    "            print(nglac, glac_str)\n",
    "\n",
    "        # Create glacier feature from ice thickness raster\n",
    "        thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "        thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "\n",
    "        gf = create_glacfeat(thick_dir, thick_fn)\n",
    "\n",
    "        # =====FILENAMES =====\n",
    "        # Add the filenames\n",
    "        fn_dict = OrderedDict()\n",
    "        # DEM\n",
    "        z1_fp = debris_prms.oggm_fp + 'dems/RGI60-' + str(region.zfill(2)) + '/'\n",
    "        z1_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_dem.tif'\n",
    "        fn_dict['z1'] = z1_fp + z1_fn\n",
    "\n",
    "        # Debris thickness and melt factors\n",
    "        hd_fn = main_glac_rgi.loc[glac_idx, 'hd_fn']\n",
    "        if '_extrap' not in hd_fn:\n",
    "            hd_fullfn = hd_fp + hd_fn\n",
    "            mf_fullfn = mf_fp + hd_fn.replace('hdts_m', 'meltfactor')\n",
    "            hdopt_prms_fullfn = hdopt_prms_fp + glac_str_noleadzero + '_hdopt_prms.csv'\n",
    "        else:\n",
    "            hd_fullfn = hd_fp_extrap + hd_fn\n",
    "            mf_fullfn = mf_fp_extrap + hd_fn.replace('hdts_m', 'meltfactor')\n",
    "            hdopt_prms_fullfn = hdopt_prms_fp_extrap + glac_str + '_hdopt_prms_extrap.csv'\n",
    "\n",
    "        fn_dict['debris_thick_ts'] = hd_fullfn\n",
    "        fn_dict['meltfactor_ts'] = mf_fullfn\n",
    "\n",
    "        # Ice thickness\n",
    "        thick_dir = debris_prms.oggm_fp + 'thickness/RGI60-' + str(region.zfill(2)) + '/'\n",
    "        thick_fn = 'RGI60-' + str(region.zfill(2)) + '.' + rgiid.split('.')[1] + '_thickness.tif'\n",
    "        fn_dict['ice_thick'] = thick_dir + thick_fn\n",
    "\n",
    "        # ===== PROCESS THE DATA =====\n",
    "        #Expand extent to include buffered region around glacier polygon\n",
    "        warp_extent = geolib.pad_extent(gf.glac_geom_extent, width=debris_prms.buff_dist)\n",
    "        if verbose:\n",
    "            print(\"Expanding extent\")\n",
    "            print(gf.glac_geom_extent)\n",
    "            print(warp_extent)\n",
    "            print(gf.aea_srs)\n",
    "\n",
    "        #Warp everything to common res/extent/proj\n",
    "        z1_gt = gdal.Open(fn_dict['z1']).GetGeoTransform()\n",
    "        z1_res = np.min([z1_gt[1], -z1_gt[5]])\n",
    "        # resampling algorithm\n",
    "        r_resampling = 'cubic'\n",
    "        ds_list = warplib.memwarp_multi_fn(fn_dict.values(), res=z1_res, extent=warp_extent, \n",
    "                                           t_srs=gf.aea_srs, verbose=verbose, r=r_resampling)\n",
    "        ds_dict = dict(zip(fn_dict.keys(), ds_list))\n",
    "        gf.ds_dict = ds_dict\n",
    "\n",
    "        if verbose:\n",
    "            print(ds_list)\n",
    "            print(fn_dict.keys())\n",
    "\n",
    "        glac_geom_mask = geolib.geom2mask(gf.glac_geom, ds_dict['z1'])\n",
    "        gf.z1 = np.ma.array(iolib.ds_getma(ds_dict['z1']), mask=glac_geom_mask)\n",
    "\n",
    "        # Debris thickness values of 0 are masked (use meltfactor mask instead)\n",
    "        gf.meltfactor_ts = np.ma.array(iolib.ds_getma(ds_dict['meltfactor_ts']), mask=glac_geom_mask)\n",
    "        gf.debris_thick_ts = np.ma.array(iolib.ds_getma(ds_dict['debris_thick_ts']), mask=glac_geom_mask)\n",
    "        gf.debris_thick_ts = np.ma.array(gf.debris_thick_ts.data, mask=gf.meltfactor_ts.mask)\n",
    "\n",
    "#             # Melt factors are masked so only calculate over areas with debris > 0\n",
    "#             gf.debris_thick_ts = np.ma.array(iolib.ds_getma(ds_dict['debris_thick_ts']), mask=glac_geom_mask)\n",
    "#             gf.meltfactor_ts = np.ma.array(iolib.ds_getma(ds_dict['meltfactor_ts']), mask=glac_geom_mask)       \n",
    "#             gf.meltfactor_ts = np.ma.array(gf.meltfactor_ts.data, mask=gf.debris_thick_ts.mask)\n",
    "\n",
    "        gf.res = geolib.get_res(ds_dict['z1'])\n",
    "\n",
    "        if verbose:\n",
    "            print('\\n\\n# z1 pixels:', gf.z1.count(), '\\n')\n",
    "            \n",
    "        # ===== ADD UNCERTAINTY OF DEBRIS THICKNESS AND MELT FACTORS ===================================\n",
    "        # ===== DEBRIS THICKNESS =====\n",
    "        # Debris thickness (lower bound)\n",
    "        hdts_bndlow = np.round(np.array(gf.debris_thick_ts.data)*100,0)\n",
    "        hdts_bndlow_int = hdts_bndlow.astype(int).copy()\n",
    "        for i in list(hd_uncertainty_dict_low.keys()):\n",
    "            hdts_bndlow[hdts_bndlow_int == i] = hd_uncertainty_dict_low[i]\n",
    "        gf.debris_thick_ts_bndlow = np.ma.array(hdts_bndlow, mask=gf.debris_thick_ts.mask)\n",
    "\n",
    "        # Debris thickness (upper bound)\n",
    "        hdts_bndhigh = np.round(np.array(gf.debris_thick_ts.data)*100,0)\n",
    "        hdts_bndhigh_int = hdts_bndhigh.astype(int).copy()\n",
    "        for i in list(hd_uncertainty_dict_high.keys()):\n",
    "            hdts_bndhigh[hdts_bndhigh_int == i] = hd_uncertainty_dict_high[i]\n",
    "        gf.debris_thick_ts_bndhigh = np.ma.array(hdts_bndhigh, mask=gf.debris_thick_ts.mask)\n",
    "        \n",
    "        # ===== MELT FACTORS =====\n",
    "        # Optimized parameters for melt factor uncertainties\n",
    "        df_opt = pd.read_csv(hdopt_prms_fullfn)\n",
    "        melt_2cm = df_opt.loc[0,'melt_mwea_2cm']\n",
    "        melt_cleanice = df_opt.loc[0,'melt_mwea_clean']\n",
    "        func_coeff = [df_opt.loc[0,'b0'], df_opt.loc[0,'k']]\n",
    "\n",
    "        # Melt factor (lower bound)\n",
    "        mf_array_low = melt_fromdebris_func(np.array(hdts_bndlow), func_coeff[0], func_coeff[1]) / melt_cleanice\n",
    "        # limit melt rates to modeled 2 cm rate\n",
    "        mf_array_low[mf_array_low > melt_2cm / melt_cleanice] = melt_2cm / melt_cleanice\n",
    "        # Linearly interpolate between 0 cm and 2 cm for the melt rate\n",
    "        def meltfactor_0to2cm_adjustment(mf, melt_clean, melt_2cm, hd):\n",
    "            \"\"\" Linearly interpolate melt factors between 0 and 2 cm \n",
    "                based on clean ice and 2 cm sub-debris melt \"\"\"\n",
    "            mf = np.nan_to_num(mf,0)\n",
    "            mf[(hd >= 0) & (hd < 0.02)] = (\n",
    "                1 + hd[(hd >= 0) & (hd < 0.02)] / 0.02 * (melt_2cm - melt_clean) / melt_clean)\n",
    "            return mf\n",
    "        mf_array_low = meltfactor_0to2cm_adjustment(mf_array_low, melt_cleanice, melt_2cm, hdts_bndlow)\n",
    "        gf.meltfactor_ts_bndlow = np.ma.array(mf_array_low, mask=gf.meltfactor_ts.mask)\n",
    "\n",
    "        # Melt factor (lower bound)\n",
    "        mf_array_high = melt_fromdebris_func(np.array(hdts_bndhigh), func_coeff[0], func_coeff[1]) / melt_cleanice\n",
    "        mf_array_high[mf_array_high > melt_2cm / melt_cleanice] = melt_2cm / melt_cleanice\n",
    "        mf_array_high = meltfactor_0to2cm_adjustment(mf_array_high, melt_cleanice, melt_2cm, np.array(hdts_bndhigh))\n",
    "        gf.meltfactor_ts_bndhigh = np.ma.array(mf_array_high, mask=gf.meltfactor_ts.mask)\n",
    "        \n",
    "        \n",
    "        # ===== PLOTS =====\n",
    "        show_plots = False\n",
    "        if debug and show_plots:\n",
    "            # DEM\n",
    "            var_full2plot = gf.z1.copy()\n",
    "            clim = malib.calcperc(var_full2plot, (2,98))\n",
    "            plot_array(var_full2plot, clim, [glac_str + ' DEM'], 'inferno', 'elev (masl)', close_fig=False)\n",
    "            # Debris thickness\n",
    "            var_full2plot = gf.debris_thick_ts.copy()\n",
    "            clim = (0,1)\n",
    "            plot_array(var_full2plot, clim, [gf.glacnum + ' hd (from ts)'], 'inferno', 'hd (m)', \n",
    "                       close_fig=False)\n",
    "            # Melt factor\n",
    "            var_full2plot = gf.meltfactor_ts.copy()\n",
    "            clim = (0,1)\n",
    "            plot_array(var_full2plot, clim, [gf.glacnum + ' meltfactor'], 'inferno', 'mf (-)',\n",
    "                       close_fig=False)\n",
    "            # Debris thickness lower bound\n",
    "            var_full2plot = gf.debris_thick_ts_bndlow.copy()\n",
    "            clim = malib.calcperc(var_full2plot, (2,98))\n",
    "            plot_array(var_full2plot, clim, [glac_str + ' Hd_ts_bndlow'], 'inferno', 'hd (ma)', close_fig=False)\n",
    "            # Debris thickness upper bound\n",
    "            var_full2plot = gf.debris_thick_ts_bndhigh.copy()\n",
    "            clim = malib.calcperc(var_full2plot, (2,98))\n",
    "            plot_array(var_full2plot, clim, [glac_str + ' Hd_ts_bndlow'], 'inferno', 'hd (ma)', close_fig=False)\n",
    "            # Melt factor lower bound\n",
    "            var_full2plot = gf.meltfactor_ts_bndlow.copy()\n",
    "            clim = (0,1)\n",
    "            plot_array(var_full2plot, clim, [gf.glacnum + ' meltfactor-bndlow'], 'inferno', 'mf (-)', close_fig=False)\n",
    "            # Melt factor upper bound\n",
    "            var_full2plot = gf.meltfactor_ts_bndhigh.copy()\n",
    "            clim = (0,1)\n",
    "            plot_array(var_full2plot, clim, [gf.glacnum + ' meltfactor-bndhigh'], 'inferno', 'mf (-)', close_fig=False)\n",
    "            \n",
    "        # Bin data\n",
    "        # ===== EXPORT THE BINNED DEBRIS THICKNESS =====\n",
    "        gf.dc_area = None\n",
    "        gf.ts = None\n",
    "        outbins_df, z_bin_edges = gf.hist_plot(bin_width=debris_prms.mb_bin_size)\n",
    "        if 'extrap' not in hd_fn:\n",
    "            outbins_df_existing_fn = glac_str + '_mb_bins_hdts.csv'\n",
    "            outbins_df_existing = pd.read_csv(debris_prms.mb_binned_fp_wdebris_hdts + outbins_df_existing_fn)\n",
    "        else:\n",
    "            outbins_df_existing_fn = glac_str + '_mb_bins_hdts_extrap.csv'\n",
    "            outbins_df_existing = pd.read_csv(debris_prms.mb_binned_fp_wdebris_hdts + '../_wdebris_hdts_extrap/' + \n",
    "                                              outbins_df_existing_fn)\n",
    "        outbins_df_existing['hd_ts_mean_m_bndlow'] = outbins_df['hd_ts_mean_m_bndlow']\n",
    "        outbins_df_existing['hd_ts_std_m_bndlow'] = outbins_df['hd_ts_std_m_bndlow']\n",
    "        outbins_df_existing['hd_ts_med_m_bndlow'] = outbins_df['hd_ts_med_m_bndlow']\n",
    "        outbins_df_existing['hd_ts_mad_m_bndlow'] = outbins_df['hd_ts_mad_m_bndlow']\n",
    "        outbins_df_existing['hd_ts_mean_m_bndhigh'] = outbins_df['hd_ts_mean_m_bndhigh']\n",
    "        outbins_df_existing['hd_ts_std_m_bndhigh'] = outbins_df['hd_ts_std_m_bndhigh']\n",
    "        outbins_df_existing['hd_ts_med_m_bndhigh'] = outbins_df['hd_ts_med_m_bndhigh']\n",
    "        outbins_df_existing['hd_ts_mad_m_bndhigh'] = outbins_df['hd_ts_mad_m_bndhigh']\n",
    "        outbins_df_existing['mf_ts_mean_bndlow'] = outbins_df['mf_ts_mean_bndlow']\n",
    "        outbins_df_existing['mf_ts_std_bndlow'] = outbins_df['mf_ts_std_bndlow']\n",
    "        outbins_df_existing['mf_ts_med_bndlow'] = outbins_df['mf_ts_med_bndlow']\n",
    "        outbins_df_existing['mf_ts_mad_bndlow'] = outbins_df['mf_ts_mad_bndlow']\n",
    "        outbins_df_existing['mf_ts_mean_bndhigh'] = outbins_df['mf_ts_mean_bndhigh']\n",
    "        outbins_df_existing['mf_ts_std_bndhigh'] = outbins_df['mf_ts_std_bndhigh']\n",
    "        outbins_df_existing['mf_ts_med_bndhigh'] = outbins_df['mf_ts_med_bndhigh']\n",
    "        outbins_df_existing['mf_ts_mad_bndhigh'] = outbins_df['mf_ts_mad_bndhigh']\n",
    "        # Output debris thickness\n",
    "        output_df_new_fn = outbins_df_existing_fn.replace('.csv','_wbnds.csv')\n",
    "        mb_bins_wbnds_fp = debris_prms.output_fp + 'mb_bins_wbnds/'\n",
    "        if not os.path.exists(mb_bins_wbnds_fp):\n",
    "            os.makedirs(mb_bins_wbnds_fp)\n",
    "        outbins_df_existing.to_csv(mb_bins_wbnds_fp + output_df_new_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]),)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(main_glac_rgi.rgino_str == '11.00001')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debris_thickness_global]",
   "language": "python",
   "name": "conda-env-debris_thickness_global-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
